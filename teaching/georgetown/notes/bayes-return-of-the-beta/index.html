<!DOCTYPE html>
<html lang="en-us">
<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <title>Ed Herbst/teaching/georgetown/notes/bayes-return-of-the-beta/</title>
    
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="robots" content="all,follow">
    <meta name="googlebot" content="index,follow,snippet,archive">
    <link rel="stylesheet" href="https://edherbst.net/hugo-theme-console/css/terminal-0.7.1.min.css">
    <link rel="stylesheet" href="https://edherbst.net/hugo-theme-console/css/animate-3.7.2.min.css">
    <link rel="stylesheet" href="https://edherbst.net/hugo-theme-console/css/console.css">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.5.0/css/all.min.css">
    <link rel="stylesheet" href="https://edherbst.net/css/custom.css">
<link rel="stylesheet" type="text/css" href="https://tikzjax.com/v1/fonts.css">
<script src="https://tikzjax.com/v1/tikzjax.js"></script>


    
      <!--[if lt IE 9]>
          <script src="https://oss.maxcdn.com/html5shiv/3.7.2/html5shiv.min.js"></script>
          <script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
      <![endif]-->
       <meta property="og:title" content="Cranking through Bayesian Calculus, Part III" />
<meta property="og:description" content="" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://edherbst.net/teaching/georgetown/notes/bayes-return-of-the-beta/" /><meta property="article:published_time" content="2025-03-14T09:51:42-04:00" />



<meta name="twitter:title" content="Cranking through Bayesian Calculus, Part III"/>
<meta name="twitter:description" content="Last time we talked about the regression model,
\begin{equation}
\label{eq:regression}
y_t = x_t&rsquo;\beta &#43; u_t, \quad u_t \sim iid N(0, \sigma^2).
\end{equation}
We focused on the &ldquo;new&rdquo; parameter, \(\sigma^2\), and talked about how to
construct a prior for it.  We then described a few different
parameterizations of the prior. Finally, we derived the posterior for
\(\sigma^2\), under the likelihood defined in (\ref{eq:regression}) with
the restriction that \(\beta=0\).  Today we&rsquo;re going to focus on jointly
estimating the two parameters of our regression model:
\((\beta,\sigma^2)\).  We&rsquo;ll refer to this vector of parameters as
\(\theta\).  Also, let&rsquo;s make it explicit that \(\beta\) is a \(k \times 1\)
vector; that is, there are \(k\) explanatory variables in our regression."/>

</head>
<body class="terminal">
    <div class="container">
        <div class="terminal-nav">
          <header class="terminal-logo">
            <div class="logo terminal-prompt">
              
              
              
              <a href='https://edherbst.net/teaching'>teaching</a>/<a href='https://edherbst.net/teaching/georgetown'>georgetown</a>/<a href='https://edherbst.net/teaching/georgetown/notes'>notes</a>/<a href='https://edherbst.net/teaching/georgetown/notes/bayes-return-of-the-beta'>bayes-return-of-the-beta</a>/</div></header>
          <nav class="terminal-menu">
            <ul vocab="https://schema.org/" typeof="BreadcrumbList">
                
                <li><a href="https://edherbst.net/" typeof="ListItem">&lt;/&gt;</a></li>
                
                <li><a href="https://edherbst.net/research/" typeof="ListItem">research</a></li>
                
                <li><a href="https://edherbst.net/teaching/" typeof="ListItem">teaching</a></li>
                
                <li><a href="https://edherbst.net/etc/" typeof="ListItem">et cetera</a></li>
                
            </ul>
          </nav>
        </div>
    </div>

    <div class="container animated zoomIn fast">
        
<h1>Cranking through Bayesian Calculus, Part III</h1>
<p>Last time we talked about the regression model,</p>
<p>\begin{equation}
\label{eq:regression}
y_t = x_t&rsquo;\beta + u_t, \quad u_t \sim iid N(0, \sigma^2).
\end{equation}</p>
<p>We focused on the &ldquo;new&rdquo; parameter, \(\sigma^2\), and talked about how to
construct a prior for it.  We then described a few different
parameterizations of the prior. Finally, we derived the posterior for
\(\sigma^2\), under the likelihood defined in (\ref{eq:regression}) with
the restriction that \(\beta=0\).  Today we&rsquo;re going to focus on jointly
estimating the two parameters of our regression model:
\((\beta,\sigma^2)\).  We&rsquo;ll refer to this vector of parameters as
\(\theta\).  Also, let&rsquo;s make it explicit that \(\beta\) is a \(k \times 1\)
vector; that is, there are \(k\) explanatory variables in our regression.</p>
<p>First, we&rsquo;ll introduce a new distribution defined jointly over
\((\beta,\sigma^2)\), which we&rsquo;ll use as our prior distribution.  To do
so, we&rsquo;ll factorize the prior as follows: \[ p(\beta,\sigma^2) =
p(\beta|\sigma^2)p(\sigma^2).  \] \((\beta,\sigma^2)\) follows a <em>normal
inverse gamma</em> distribution with parameters \((\nu_0, s_0^2, \mu_0,
V_0)\) if \(\sigma^2\) follows an inverse gamma distribution with
parameters \((\nu_0, s_0^2)\) and \(\beta\) <em>conditional</em> on
\(\sigma^2\) follows a normal distribution with mean \(\mu_0\) and
variance \(\sigma^2V_0.\) Use the above factorization, the joint
density of the distribution can be written as:</p>
<p>\begin{multline*}
p(\beta,\sigma^2) = (2\pi)^{-k/2}
[\mbox{det}(\sigma^2 V_0)]^{-1/2}\exp\left\{-\frac12 (\beta -
\mu_0)&rsquo;[\sigma^2 V_0]^{-1}(\beta - \mu_0)\right\} \\ \times
\frac{\nu_0/2}{\Gamma(\nu_0/2)}s_0^{\nu_0}(1/\sigma^2)^{\nu_0/2+1}\exp\left\{-\nu_0 s_0^2
/ (2\sigma^2)\right\}
\end{multline*}</p>
<p><strong>Problem 1:</strong> Write two scripts is <code>python</code> or <code>R</code> that: (1) generate
draws from this distribution and (2) evaluate the log pdf of the
distribution, given some values.</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#080;font-style:italic">#test</span>
</span></span></code></pre></div><p>Note that in our formulation, we&rsquo;ve constructed \(\beta\) conditional on
\(\sigma^2\).  It&rsquo;s also interesting to examine the <em>marginal</em> distribution of \(\beta\),
\[
p(\beta) = \int p(\beta,\sigma^2)d\sigma^2.
\]
<strong>Problem 2:</strong> Derive the marginal distribution of \(\beta\) by
integrating out \(\sigma^2\).  Validate your derivation by comparing a
density estimated from the simulations in Problem 1 to the analytic
formulation.  What is the name of this distribution?</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#080;font-style:italic">#test</span>
</span></span></code></pre></div><p>The normal inverse gamma prior is convenient because it&rsquo;s <em>conjugate</em>
for the normal regression model in (\ref{eq:regression}).  This means
that the posterior distribution of the parameters is also a normal
inverse gamma distribution.</p>
<p><strong>Problem 3:</strong> Derive the posterior distribution for the model in
(\ref{eq:regression}).  Use a normal inverse gamma prior with
parameters \((\nu_0, s_0^2, \mu_0, V_0)\).  For notation, let \(X =
[x_1, \ldots, x_T]&rsquo;\) and \(Y = [y_1,\ldots,y_T]&rsquo;\).</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#080;font-style:italic">#test</span>
</span></span></code></pre></div><p>Let&rsquo;s run a Bayesian regression!  The data in the table below come
from T. Haavelmo, &ldquo;Methods of Measuring the Marginal Propensity to
Consume,&rdquo; <em>J. Am. Statist. Assoc</em>, 42, p. 88 (1947).  Using
(\ref{eq:regression}) to relate income, \(y_t\), to a constant and
&ldquo;autonomous&rdquo; investment, the independent variable.  The coefficient
associated with investment is termed the investment multiplier.</p>
<p><strong>Problem 4:</strong> Pick a parameterization of the normal inverse gamma
distribution that is not very informative; that is, it doesn&rsquo;t impose
strong beliefs about the plausible values one the coefficients.
Let&rsquo;s center the prior for \(\beta\) at \(\mu_0 = 0\), and for the
inverse gamma portion set \(s_0^2 =600\). What should you do with
\(\nu_0\) and \(V_0\)?  Construct the posterior distribution for \(\beta\)
and \(\sigma^2\).  What is the posterior mean of \(\beta_2\), the
coefficient associated with investment?  What happens when you
increase the &ldquo;strength&rdquo; of the prior, by increasing \(\nu_0\) or
decreasing \(V_0\)?</p>
<p><a id="table--HAAVELMO"></a></p>
<div class="table-caption">
  <span class="table-number"><a href="#table--HAAVELMO">Table 1</a>:</span>
  Haavelmo's Data on Income and Investment \vspace*{0.1in}
</div>
<table>
  <thead>
      <tr>
          <th>Year</th>
          <th>Income</th>
          <th>Investment</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td>1922</td>
          <td>433</td>
          <td>39</td>
      </tr>
      <tr>
          <td>1923</td>
          <td>483</td>
          <td>60</td>
      </tr>
      <tr>
          <td>1924</td>
          <td>479</td>
          <td>42</td>
      </tr>
      <tr>
          <td>1925</td>
          <td>486</td>
          <td>52</td>
      </tr>
      <tr>
          <td>1926</td>
          <td>494</td>
          <td>47</td>
      </tr>
      <tr>
          <td>1927</td>
          <td>498</td>
          <td>51</td>
      </tr>
      <tr>
          <td>1928</td>
          <td>511</td>
          <td>45</td>
      </tr>
      <tr>
          <td>1929</td>
          <td>534</td>
          <td>60</td>
      </tr>
      <tr>
          <td>1930</td>
          <td>478</td>
          <td>39</td>
      </tr>
      <tr>
          <td>1931</td>
          <td>440</td>
          <td>41</td>
      </tr>
      <tr>
          <td>1932</td>
          <td>372</td>
          <td>22</td>
      </tr>
      <tr>
          <td>1933</td>
          <td>381</td>
          <td>17</td>
      </tr>
      <tr>
          <td>1934</td>
          <td>419</td>
          <td>27</td>
      </tr>
      <tr>
          <td>1935</td>
          <td>449</td>
          <td>33</td>
      </tr>
      <tr>
          <td>1936</td>
          <td>511</td>
          <td>48</td>
      </tr>
      <tr>
          <td>1937</td>
          <td>520</td>
          <td>51</td>
      </tr>
      <tr>
          <td>1938</td>
          <td>477</td>
          <td>33</td>
      </tr>
      <tr>
          <td>1939</td>
          <td>517</td>
          <td>46</td>
      </tr>
      <tr>
          <td>1940</td>
          <td>548</td>
          <td>54</td>
      </tr>
      <tr>
          <td>1941</td>
          <td>629</td>
          <td>100</td>
      </tr>
  </tbody>
</table>



<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  TeX: { equationNumbers: { autoNumber: "AMS" },
         extensions: ["AMSmath.js", "AMSsymbols.js"] },
  tex2jax: {
      inlineMath: [['$','$'],['\\(','\\)']],
      displayMath: [['$$','$$'], ['\\[', '\\]']],
    processEscapes: true,
    processEnvironments: true,
    skipTags: ['script', 'noscript', 'style', 'textarea', 'pre']
  }
});
</script>
<script type="text/javascript"
  src="//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>


        <div class="footer">
    Powered by <a href="https://gohugo.io/">Hugo</a> with
    <a href="https://github.com/mrmierzejewski/hugo-theme-console/">Console Theme</a>. 
</div>

    </div>
  </body>
</html>
