<!DOCTYPE html>
<html lang="en-us">
<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <title>Ed Herbst/teaching/georgetown/lectures/lecture-seven-dsge-state-space/</title>
    
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="robots" content="all,follow">
    <meta name="googlebot" content="index,follow,snippet,archive">
    <link rel="stylesheet" href="https://edherbst.net/hugo-theme-console/css/terminal-0.7.1.min.css">
    <link rel="stylesheet" href="https://edherbst.net/hugo-theme-console/css/animate-3.7.2.min.css">
    <link rel="stylesheet" href="https://edherbst.net/hugo-theme-console/css/console.css">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.5.0/css/all.min.css">
    <link rel="stylesheet" href="https://edherbst.net/css/custom.css">
<link rel="stylesheet" type="text/css" href="https://tikzjax.com/v1/fonts.css">
<script src="https://tikzjax.com/v1/tikzjax.js"></script>


    
      <!--[if lt IE 9]>
          <script src="https://oss.maxcdn.com/html5shiv/3.7.2/html5shiv.min.js"></script>
          <script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
      <![endif]-->
       <meta property="og:title" content="Intro to DSGE &#43; State Space Models" />
<meta property="og:description" content="" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://edherbst.net/teaching/georgetown/lectures/lecture-seven-dsge-state-space/" /><meta property="article:published_time" content="2025-03-13T17:49:57-04:00" />



<meta name="twitter:title" content="Intro to DSGE &#43; State Space Models"/>
<meta name="twitter:description" content="Intro
Background

Textbook treatments: Woodford (2003), Galí (2008)

Key empirical papers: Ireland (2004),  Christiano, Eichenbaum, and Evans (2005), Smets and Wouters (2007), An and Schorfheide (2007),

Frequentist estimation: Harvey (1991), Hamilton (1994),

Bayesian estimation: Herbst and Schorfheide (2015)

A DSGE Model
Small-Scale DSGE Model

Intermediate and final goods producers

Households

Monetary and fiscal policy

Exogenous processes

Equilibrium Relationships

Final Goods Producers

Perfectly competitive firms combine
a continuum of intermediate goods:
\[
Y_t = \left( \int_0^1 Y_t(j)^{1-\nu} dj \right)^{\frac{1}{1-\nu}}.
\]
Firms take input prices \(P_t(j)\) and output prices \(P_t\) as given; maximize profits
\[
\Pi_t =  P_t \left( \int_0^1 Y_t(j)^{1-\nu} dj \right)^{\frac{1}{1-\nu}} - \int_{0}^1 P_t(j)Y_t(j)dj.
\]
Demand for intermediate good \(j\):
\[
Y_t(j) = \left( \frac{P_t(j)}{P_t} \right)^{-1/\nu} Y_t.
\]
Zero-profit condition implies
\[
P_t = \left( \int_0^1 P_t(j)^{\frac{\nu-1}{\nu}} dj \right)^{\frac{\nu}{\nu-1}}.
\]

Intermediate Goods Producers

Intermediate good \(j\) is produced by a monopolist according to:
\[
Y_t(j) = A_t N_t(j).
\]
Nominal price stickiness via quadratic price adjustment costs
\[
AC_t(j) = \frac{\phi}{2} \left( \frac{ P_t(j) }{ P_{t-1}(j)} - \pi \right)^2 Y_t(j).
\]
Firm \(j\)
chooses its labor input \(N_t(j)\) and the price \(P_t(j)\) to maximize
the present value of future profits:
\[ \mathbb{E}_t \bigg[
\sum_{s=0}^\infty \beta^{s} Q_{t&#43;s|t} \bigg(
\frac{P_{t&#43;s}(j)}{P_{t&#43;s}} Y_{t&#43;s}(j) - W_{t&#43;s} N_{t&#43;s}(j) - AC_{t&#43;s}(j) \bigg) \bigg].
\]

Households


Household derives disutility from hours worked \(H_t\) and maximizes"/>

</head>
<body class="terminal">
    <div class="container">
        <div class="terminal-nav">
          <header class="terminal-logo">
            <div class="logo terminal-prompt">
              
              
              
              <a href='https://edherbst.net/teaching'>teaching</a>/<a href='https://edherbst.net/teaching/georgetown'>georgetown</a>/<a href='https://edherbst.net/teaching/georgetown/lectures'>lectures</a>/<a href='https://edherbst.net/teaching/georgetown/lectures/lecture-seven-dsge-state-space'>lecture-seven-dsge-state-space</a>/</div></header>
          <nav class="terminal-menu">
            <ul vocab="https://schema.org/" typeof="BreadcrumbList">
                
                <li><a href="https://edherbst.net/" typeof="ListItem">&lt;/&gt;</a></li>
                
                <li><a href="https://edherbst.net/research/" typeof="ListItem">research</a></li>
                
                <li><a href="https://edherbst.net/teaching/" typeof="ListItem">teaching</a></li>
                
                <li><a href="https://edherbst.net/etc/" typeof="ListItem">et cetera</a></li>
                
            </ul>
          </nav>
        </div>
    </div>

    <div class="container animated zoomIn fast">
        
<h1>Intro to DSGE &#43; State Space Models</h1>
<h2 id="intro">Intro</h2>
<h3 id="background">Background</h3>
<ul>
<li><em>Textbook treatments:</em> <a href="#citeproc_bib_item_11">Woodford (2003)</a>, <a href="#citeproc_bib_item_4">Galí (2008)</a>
<br></li>
<li><em>Key empirical papers</em>: <a href="#citeproc_bib_item_8">Ireland (2004)</a>,  <a href="#citeproc_bib_item_2">Christiano, Eichenbaum, and Evans (2005)</a>, <a href="#citeproc_bib_item_10">Smets and Wouters (2007)</a>, <a href="#citeproc_bib_item_1">An and Schorfheide (2007)</a>,
<br></li>
<li><em>Frequentist estimation:</em> <a href="#citeproc_bib_item_6">Harvey (1991)</a>, <a href="#citeproc_bib_item_5">Hamilton (1994)</a>,
<br></li>
<li><em>Bayesian estimation:</em> <a href="#citeproc_bib_item_7">Herbst and Schorfheide (2015)</a></li>
</ul>
<h2 id="a-dsge-model">A DSGE Model</h2>
<h3 id="small-scale-dsge-model">Small-Scale DSGE Model</h3>
<ul>
<li>Intermediate and final goods producers
<br></li>
<li>Households
<br></li>
<li>Monetary and fiscal policy
<br></li>
<li>Exogenous processes
<br></li>
<li>Equilibrium Relationships</li>
</ul>
<h3 id="final-goods-producers">Final Goods Producers</h3>
<ul>
<li>Perfectly competitive firms combine
a continuum of intermediate goods:
\[
Y_t = \left( \int_0^1 Y_t(j)^{1-\nu} dj \right)^{\frac{1}{1-\nu}}.
\]</li>
<li>Firms take input prices \(P_t(j)\) and output prices \(P_t\) as given; maximize profits
\[
\Pi_t =  P_t \left( \int_0^1 Y_t(j)^{1-\nu} dj \right)^{\frac{1}{1-\nu}} - \int_{0}^1 P_t(j)Y_t(j)dj.
\]</li>
<li>Demand for intermediate good \(j\):
\[
Y_t(j) = \left( \frac{P_t(j)}{P_t} \right)^{-1/\nu} Y_t.
\]</li>
<li>Zero-profit condition implies
\[
P_t = \left( \int_0^1 P_t(j)^{\frac{\nu-1}{\nu}} dj \right)^{\frac{\nu}{\nu-1}}.
\]</li>
</ul>
<h3 id="intermediate-goods-producers">Intermediate Goods Producers</h3>
<ul>
<li>Intermediate good \(j\) is produced by a monopolist according to:
\[
Y_t(j) = A_t N_t(j).
\]</li>
<li>Nominal price stickiness via quadratic price adjustment costs
\[
AC_t(j) = \frac{\phi}{2} \left( \frac{ P_t(j) }{ P_{t-1}(j)} - \pi \right)^2 Y_t(j).
\]</li>
<li>Firm \(j\)
chooses its labor input \(N_t(j)\) and the price \(P_t(j)\) to maximize
the present value of future profits:
\[ \mathbb{E}_t \bigg[
\sum_{s=0}^\infty \beta^{s} Q_{t+s|t} \bigg(
\frac{P_{t+s}(j)}{P_{t+s}} Y_{t+s}(j) - W_{t+s} N_{t+s}(j) - AC_{t+s}(j) \bigg) \bigg].
\]</li>
</ul>
<h3 id="households">Households</h3>
<ul>
<li>
<p>Household derives disutility from hours worked \(H_t\) and maximizes</p>
<p>\begin{eqnarray*}
\lefteqn{ \mathbb{E}_t \bigg[ \sum_{s=0}^\infty \beta^s \bigg( \frac{ (C_{t+s}/A_{t+s})^{1-\tau} -1 }{1-\tau} } \\
&amp;&amp;+ \chi_M \ln \left( \frac{M_{t+s}}{P_{t+s}} \right) - \chi_H H_{t+s} \bigg) \bigg].
\end{eqnarray*}</p>
</li>
<li>
<p>Budget constraint:</p>
<p>\begin{eqnarray*}
\lefteqn{P_t C_{t} + B_{t} + M_t + T_t} \\
&amp;=&amp; P_t W_t H_{t} + R_{t-1}B_{t-1} + M_{t-1} + P_t D_{t} + P_t SC_t.
\end{eqnarray*}</p>
</li>
</ul>
<h3 id="monetary-and-fiscal-policy">Monetary and Fiscal Policy</h3>
<ul>
<li>
<p>Central bank adjusts money supply to attain desired interest rate.</p>
</li>
<li>
<p>Monetary policy rule:</p>
<p>\begin{eqnarray*}
R_t &amp;=&amp; R_t^{*, 1-\rho_R} R_{t-1}^{\rho_R} e^{\epsilon_{R,t}} \\
R_t^* &amp;=&amp; r \pi^* \left( \frac{\pi_t}{\pi^*} \right)^{\psi_1} \left( \frac{Y_t}{Y_t^*} \right)^{\psi_2}
\end{eqnarray*}</p>
</li>
<li>
<p>Fiscal authority consumes fraction of aggregate output: \(G_t = \zeta_t Y_t\).</p>
</li>
<li>
<p>Government budget constraint:
\[
P_t G_t + R_{t-1} B_{t-1} + M_{t-1} = T_t + B_t + M_t.
\]</p>
</li>
</ul>
<h3 id="exogenous-processes">Exogenous Processes</h3>
<ul>
<li>Technology:
\[
\ln A_t = \ln \gamma + \ln A_{t-1} + \ln z_t, \quad
\ln z_t = \rho_z \ln z_{t-1} + \epsilon_{z,t}.
\]</li>
<li>Government spending / aggregate demand: define \(g_t = 1/(1-\zeta_t)\); assume
\[
\ln g_t = (1-\rho_g) \ln g + \rho_g \ln g_{t-1} + \epsilon_{g,t}.
\]</li>
<li>Monetary policy shock \(\epsilon_{R,t}\) is assumed to be serially uncorrelated.</li>
</ul>
<h3 id="equilibrium-conditions">Equilibrium Conditions</h3>
<ul>
<li>
<p>Consider the symmetric equilibrium in which all intermediate goods producing
firms make identical choices; omit \(j\) subscript.</p>
</li>
<li>
<p>Market clearing:
\[
Y_t = C_t + G_t + AC_t \quad \mbox{and} \quad H_t = N_t.
\]</p>
</li>
<li>
<p>Complete markets:
\[
Q_{t+s|t} = (C_{t+s}/C_t)^{-\tau}(A_t/A_{t+s})^{1-\tau}.
\]</p>
</li>
<li>
<p>Consumption Euler equation and New Keynesian Phillips curve:</p>
<p>\begin{eqnarray*}
1 &amp;=&amp; \beta \mathbb{E}_t \left[ \left( \frac{ C_{t+1} /A_{t+1} }{C_t/A_t} \right)^{-\tau} \frac{A_t}{A_{t+1}} \frac{R_t}{\pi_{t+1}} \right] \label{eq_dsge1HHopt} \\
1 &amp;=&amp;
\phi (\pi_t - \pi) \left[ \left( 1 - \frac{1}{2\nu} \right) \pi_t + \frac{\pi}{2 \nu} \right] \label{eq_dsge1Firmopt}\\
&amp;&amp; - \phi \beta \mathbb{E}_t \left[ \left( \frac{ C_{t+1} /A_{t+1} }{C_t/A_t} \right)^{-\tau} \frac{ Y_{t+1} /A_{t+1} }{Y_t/A_t}
(\pi_{t+1} - \pi) \pi_{t+1} \right] \nonumber \\
&amp;&amp; + \frac{1}{\nu} \left[ 1 - \left( \frac{C_t}{A_t} \right)^\tau \right]. \nonumber
\end{eqnarray*}</p>
</li>
</ul>
<h3 id="equilibrium-conditions-continued">Equilibrium Conditions &ndash; Continued</h3>
<ul>
<li>In the absence of nominal rigidities \((\phi = 0)\)
aggregate output is given by
\[
Y_t^* = (1-\nu)^{1/\tau} A_t g_t,
\]
which is the target level of output that appears in the monetary policy rule.</li>
</ul>
<h3 id="steady-state">Steady State</h3>
<ul>
<li>
<p>Set \(\epsilon_{R,t}\), \(\epsilon_{g,t}\), and \(\epsilon_{z,t}\)
to zero at all times.</p>
</li>
<li>
<p>Because technology \(\ln A_t\) evolves according
to a random walk with drift \(\ln \gamma\), consumption and output need
to be detrended for a steady state to exist.</p>
</li>
<li>
<p>Let
\[
c_t = C_t/A_t, \quad y_t = Y_t/A_t, \quad
y^*_t = Y^*_t/A_t.
\]</p>
</li>
<li>
<p>Steady state is given by:</p>
<p>\begin{eqnarray*}
\pi &amp;=&amp; \pi^*, \quad r = \frac{\gamma}{\beta}, \quad R = r
\pi^*, \\
c &amp;=&amp; (1-\nu)^{1/\tau}, \quad  y = g c =
y^*.
\end{eqnarray*}</p>
</li>
</ul>
<h2 id="solving-dsge-models">Solving DSGE Models</h2>
<h3 id="solving-dsge-models">Solving DSGE Models</h3>
<ul>
<li>Derive nonlinear equilibrium conditions:
<ul>
<li>System of nonlinear expectational difference equations;</li>
<li>transversality conditions.</li>
</ul>
</li>
<li>Find solution(s) of system of expectational difference methods:
<ul>
<li>Global (nonlinear) approximation</li>
<li>Local approximation near steady state</li>
</ul>
</li>
<li>\textcolor{blue}{We will focus on log-linear approximations around the steady state.}</li>
<li>More detail in: <a href="#citeproc_bib_item_3">Fernandez-Villaverde, Rubio-Ramirez, and Schorfheide (2016)</a>: ``Solution and Estimation Methods for DSGE Models.''</li>
</ul>
<h3 id="what-is-a-local-approximation">What is a Local Approximation?</h3>
<ul>
<li>In a nutshell&hellip; consider the backward-looking model
\[
y_t = f(y_{t-1},\sigma \epsilon_t).
\]</li>
<li>Guess that the solution is of the form
\[
y_t = y_t^{(0)} + \sigma y_t^{(1)} + o(\sigma).
\]</li>
<li>Steady state:
\[
y_t^{(0)} = y^{(0)} = f(y^{(0)},0)
\]</li>
<li>Suppose \(y^{(0)}=0\). Expand \(f(\cdot)\) around \(\sigma=0\):
\[
f(y_{t-1},\sigma \epsilon_t)
= f_y y_{t-1} + f_\epsilon \sigma \epsilon_t + o(|y_{t-1}|) + o(\sigma)
\]</li>
<li>Now plug-in conjectured solution:
\[
\sigma y_t^{(1)}
=  f_y \sigma y_{t-1}^{(1)} + f_\epsilon \sigma \epsilon_t + o(\sigma)
\]</li>
<li>Deduce that \(y_t^{(1)} = f_y y_{t-1}^{(1)} + f_\epsilon \epsilon_t\)</li>
</ul>
<h3 id="what-is-a-log-linear-approximation">What is a Log-Linear Approximation?</h3>
<ul>
<li>
<p>Consider a Cobb-Douglas production function: \(Y_t = A_t K_t^\alpha N_t^{1-\alpha}\).</p>
</li>
<li>
<p>\textcolor{red}{Linearization} around \(Y_*\), \(A_*\), \(K_*\), \(N_*\):</p>
<p>\begin{eqnarray*}
Y_t-Y_* &amp;\approx&amp; K_*^\alpha N_*^{1-\alpha}(A_t - A_*)
+ \alpha A_* K_*^{\alpha-1} N_*^{1-\alpha} (K_t-K_*) \\
&amp;&amp;	  + (1-\alpha) A_* K_*^\alpha N_*^{-\alpha} (N_t-N_*)
\end{eqnarray*}</p>
</li>
<li>
<p>\textcolor{blue}{Log-linearization:} Let \(f(x) = f(e^v)\) and linearize
with respect to \(v\):
\[
f(e^v) \approx f(e^{v_*}) + e^{v_*} f&rsquo;(e^{v_*}) (v-v_*).
\]
Thus:
\[
f(x) \approx f(x_*) + x_* f&rsquo;(x_*){\color{blue} (\ln x/x_*)} = f(x_*) + f&rsquo;(x_*) {\color{blue} \tilde{x}}
\]</p>
</li>
<li>
<p>Cobb-Douglas production function (here relationship is exact):
\[
\tilde{Y}_t = \tilde{A}_t + \alpha \tilde{K}_t + (1-\alpha) \tilde{N_t}
\]</p>
</li>
</ul>
<h3 id="loglinearization-of-new-keynesian-model">Loglinearization of New Keynesian Model</h3>
<ul>
<li>Consumption Euler equation:
\[
\hat{y}_{t} =  \mathbb{E}_t[\hat y_{t+1}] - \frac{1}{\tau} \bigg( \hat R_t -  \mathbb{E}_t[\hat\pi_{t+1}] - \mathbb{E}_t[\hat{z}_{t+1}] \bigg) + \hat{g}_t - \mathbb{E}_t[\hat{g}_{t+1}]
\]</li>
<li>New Keynesian Phillips curve:
\[
\hat \pi_t = \beta \mathbb{E}_t[\hat \pi_{t+1}] + \kappa (\hat y_t- \hat g_t),
\]
where
\[
\kappa = \tau \frac{1 -\nu}{ \nu \pi^2 \phi }
\]</li>
<li>Monetary policy rule:
\[
\hat R_{t} = \rho_R \hat R_{t-1} + (1-\rho_R) \psi_1 \hat \pi_{t} + (1-\rho_R) \psi_2 \left( \hat y_{t} - \hat g_t \right)+ \epsilon_{R,t}
\]</li>
</ul>
<h3 id="canonical-linear-rational-expectations-system">Canonical Linear Rational Expectations System</h3>
<ul>
<li>Define
\[
x_t  = [ \hat y_t, \hat \pi_t, \hat R_t, \epsilon_{R,t}, \hat{g}_t, \hat z_t  ]&rsquo;.
\]</li>
<li>Augment \(x_t\) by
\(\mathbb{E}_t[\hat{y}_{t+1}]\) and \(\mathbb{E}_t[\hat{\pi}_{t+1}]\).</li>
<li>Define
\[
s_t = \big[ x_t&rsquo;, \mathbb{E}_t[\hat{y}_{t+1}], \mathbb{E}_t[\hat{\pi}_{t+1}] \big]&rsquo;.
\]</li>
<li>Define rational expectations forecast errors forecast errors for inflation and output. Let
\[
\eta_{y,t} = y_t - \mathbb{E}_{t-1}[\hat{y}_t], \quad \eta_{\pi,t} = \pi_t - \mathbb{E}_{t-1}[\hat{\pi}_t].
\]</li>
<li>Write system in canonical form <a href="#citeproc_bib_item_9">Sims (2002)</a>:
\[
\Gamma_0 s_t = \Gamma_1 s_{t-1} + \Psi \epsilon_t + \Pi \eta_t.
\]</li>
</ul>
<h3 id="how-can-one-solve-linear-rational-expectations-systems-a-simple-example">How Can One Solve Linear Rational Expectations Systems? A Simple Example</h3>
<ul>
<li>
<p>Consider</p>
<p>\begin{eqnarray}
y_t = \frac{1}{\theta} \EE_t[y_{t+1}] + \epsilon_t,
\label{eq_yex}
\end{eqnarray}</p>
<p>where \(\epsilon_t \sim iid(0,1)\) and \(\theta \in \Theta = [0,2]\).
<br></p>
</li>
<li>
<p>Introduce conditional expectation \(\xi_t = \mathbb E_{t}[y_{t+1}]\) and forecast error \(\eta_t = y_t - \xi_{t-1}\).
<br></p>
</li>
<li>
<p>Thus,</p>
<p>\begin{eqnarray}
\xi_t = \theta \xi_{t-1} - \theta \epsilon_t + \theta \eta_t. \label{eq_lreex}
\end{eqnarray}</p>
</li>
</ul>
<h3 id="a-simple-example">A Simple Example</h3>
<ul>
<li>
<p>Determinacy: \(\theta &gt; 1\). Then only stable solution:</p>
<p>\begin{eqnarray}
\xi_t = 0, \quad \eta_t = \epsilon_t, \quad  y_t = \epsilon_t
\end{eqnarray}</p>
</li>
<li>
<p>Indeterminacy: \(\theta \le 1\) the stability requirement imposes no restrictions on forecast error:</p>
<p>\begin{eqnarray}
\eta_t = \widetilde{M} \epsilon_t + \zeta_t.
\end{eqnarray}</p>
</li>
<li>
<p>For simplicity assume now  \(\zeta_t = 0\). Then</p>
<p>\begin{eqnarray}
y_t - \theta y_{t-1} = \widetilde{M} \epsilon_t - \theta \epsilon_{t-1}.
\label{eq_arma11}
\end{eqnarray}</p>
</li>
<li>
<p>General solution methods for LREs: Blanchard and Kahn (1980), King and Watson (1998), Uhlig (1999),
Anderson (2000), Klein (2000), Christiano (2002), Sims (2002).</p>
</li>
</ul>
<h3 id="solving-a-more-general-system">Solving a More General System</h3>
<ul>
<li>
<p>Canonical form:</p>
<p>\begin{equation}
\Gamma_{0}(\theta)s_{t}=\Gamma_{1}(\theta) s_{t-1}+\Psi
(\theta)\epsilon_t+\Pi (\theta)\eta_{t},
\end{equation}</p>
</li>
<li>
<p>The system can be rewritten as</p>
<p>\begin{equation}
s_{t}=\Gamma _{1}^{\ast }(\theta) s_{t-1}+\Psi^{\ast}(\theta)\epsilon_{t}
+\Pi^{\ast }(\theta)\eta_{t}.
\end{equation}</p>
</li>
<li>
<p>Replace \(\Gamma _{1}^{\ast }\) by  \(J\Lambda J^{-1}\) and define  \(w_{t}=J^{-1}s_{t}\).</p>
</li>
<li>
<p>To deal with repeated eigenvalues and non-singular \(\Gamma_0\) we use Generalized Complex Schur Decomposition (QZ) in practice.</p>
</li>
<li>
<p>Let the \(i\)&rsquo;th element of \(w_{t}\) be \(w_{i,t}\) and denote the \(i\)&rsquo;th
row of \(J^{-1}\Pi ^{\ast }\) and \(J^{-1}\Psi ^{\ast }\) by \([J^{-1}\Pi
^{\ast }]_{i.}\) and \([J^{-1}\Psi ^{\ast }]_{i.}\), respectively.</p>
</li>
</ul>
<h3 id="solving-a-more-general-system">Solving a More General System</h3>
<ul>
<li>
<p>Rewrite model:</p>
<p>\begin{equation}
w_{i,t}=\lambda_{i}w_{i,t-1}+[J^{-1}\Psi ^{\ast }]_{i.} \epsilon_{t}+[J^{-1}\Pi ^{\ast }]_{i.}\eta _{t}.  \label{eq_wit1}
\end{equation}</p>
</li>
<li>
<p>Define the set of stable AR(1) processes as</p>
<p>\begin{equation}
I_{s}(\theta)=\bigg\{i\in \{1,\ldots n\}\bigg|\left\vert \lambda_{i}(\theta)\right\vert	 \le 1\bigg\}
\end{equation}</p>
</li>
<li>
<p>Let \(I_{x}(\theta)\) be its complement. Let \(\Psi _{x}^{J}\) and \(\Pi_{x}^{J}\) be the matrices composed of the row vectors \([J^{-1}\Psi^{\ast }]_{i.}\) and \([J^{-1}\Pi ^{\ast }]_{i.}\) that correspond to unstable eigenvalues, i.e., \(i\in I_{x}(\theta)\).</p>
</li>
<li>
<p>Stability condition:</p>
<p>\begin{equation}
\Psi_{x}^{J}\epsilon_{t}+\Pi_{x}^{J}\eta_{t}=0  \label{eq_stabcond}
\end{equation}</p>
<p>for all \(t\).</p>
</li>
</ul>
<h3 id="solving-a-more-general-system">Solving a More General System</h3>
<ul>
<li>
<p>Solving for \(\eta_t\). Define</p>
<p>\begin{eqnarray}
\Pi_x^J &amp;=&amp; \left[
\begin{array}{cc}
U_{.1} &amp; U_{.2}
\end{array}
\right] \left[
\begin{array}{cc}
D_{11} &amp; 0 \\
0 &amp; 0
\end{array}
\right] \left[
\begin{array}{c}
V_{.1}^{\prime } \\
V_{.2}^{\prime }
\end{array}
\right] \label{eq_svd} \\
&amp;=&amp;\underbrace{U}_{m\times m}\underbrace{D}_{m\times k}\underbrace{V^{\prime }}_{k\times k} \nonumber \\
&amp;=&amp;\underbrace{U_{.1}}_{m\times r}\underbrace{D_{11}}_{r\times r}\underbrace{V_{.1}^{\prime }}_{r\times k}. \nonumber
\end{eqnarray}</p>
</li>
<li>
<p>If there exists a solution to Eq.~(\ref{eq_stabcond}) that expresses the forecast errors as function of the fundamental shocks \(\epsilon_t\) and sunspot shocks \(\zeta_t\), it is of the form</p>
<p>\begin{eqnarray}
\eta_t &amp;=&amp; \eta_1 \epsilon_t + \eta_2 \zeta_t  \label{eq_etasol} \\
&amp;=&amp; ( - V_{.1}D_{11}^{-1} U_{.1}^{\prime}\Psi_x^J + V_{.2} \widetilde{M}) \epsilon_t +
V_{.2} M_\zeta \zeta_t,	 \notag
\end{eqnarray}</p>
<p>where \(\widetilde{M}\) is
an \((k-r) \times l\) matrix, \(M_\zeta\) is a \((k-r) \times p\) matrix, and the dimension
of \(V_{.2}\) is \(k\times (k-r)\). The solution is unique if \(k = r\) and \(V_{.2}\)
is zero.</p>
</li>
</ul>
<h3 id="proposition">Proposition</h3>
<p>If there exists a solution to Eq. (\ref{eq_stabcond}) that expresses the forecast errors as function of the
fundamental shocks \(\epsilon_t\) and sunspot shocks \(\zeta_t\), it is of the form</p>
<p>\begin{eqnarray}
\eta_t &amp;=&amp; \eta_1 \epsilon_t + \eta_2 \zeta_t  \label{eq_etasol} \\
&amp;=&amp; ( - V_{.1}D_{11}^{-1} U_{.1}^{\prime}\Psi_x^J + V_{.2} \widetilde{M}) \epsilon_t +
V_{.2} M_\zeta \zeta_t,	 \notag
\end{eqnarray}</p>
<p>where \(\widetilde{M}\) is
an \((k-r) \times l\) matrix, \(M_\zeta\) is a \((k-r) \times p\) matrix, and the dimension
of \(V_{.2}\) is \(k\times (k-r)\). The solution is unique if \(k = r\) and \(V_{.2}\)
is zero.</p>
<h3 id="at-the-end-of-the-day-dot-dot-dot">At the End of the Day&hellip;</h3>
<ul>
<li>We obtain a transition equation for the vector \(s_t\):
\[
s_{t} = T(\theta) s_{t-1} + R(\theta) \epsilon_{t}.
\]</li>
<li>The coefficient matrices \(T(\theta)\) and \(R(\theta)\) are
functions of the parameters of the DSGE model.</li>
</ul>
<h3 id="measurement-equation">Measurement Equation</h3>
<ul>
<li>
<p>Relate model variables \(s_t\) to observables \(y_t\).</p>
</li>
<li>
<p>In NK model:</p>
<p>\begin{eqnarray*}
YGR_t  &amp;=&amp; \gamma^{(Q)} + 100(\hat y_t - \hat y_{t-1} + \hat z_t) \label{eq_dsge1measure}\\
INFL_t &amp;=&amp; \pi^{(A)} + 400 \hat \pi_t  \nonumber \\
INT_t  &amp;=&amp; \pi^{(A)} + r^{(A)} + 4 \gamma^{(Q)} + 400 \hat R_t . \nonumber
\end{eqnarray*}</p>
<p>where
\[
\gamma = 1+ \frac{\gamma^{(Q)}}{100}, \quad \beta = \frac{1}{1+ r^{(A)}/400}, \quad
\pi = 1 + \frac{\pi^{(A)}}{400} .
\]</p>
</li>
<li>
<p>More generically:
\[
y_t = D(\theta) + Z(\theta) s_t \underbrace{+u_t}_{\displaystyle \mbox{optional}}.
\]
The state and measurement equations define a <em>State Space Model</em>.</p>
</li>
</ul>
<h2 id="state-space-models-and-the-kalman-filter">State Space Models and The Kalman Filter</h2>
<h3 id="state-space-models">State Space Models</h3>
<ul>
<li>State space models form a very general class of models that
encompass many of the specifications that we encountered earlier.</li>
<li>ARMA models and linearized DSGE models can be written in state space form.</li>
</ul>
 <br>
A state space model consists of
<ul>
<li>a measurement equation that relates an <em>unobservable</em> state vector \(s_t\) to the <em>observables</em> \(y_t\),</li>
<li>a transition equation that describes the evolution of the state vector \(s_t\).</li>
</ul>
<h3 id="measurement-equation">Measurement Equation</h3>
<p>The measurement equation is of the form</p>
<p>\begin{eqnarray}
y_t = Z_{t|t-1} s_t + d_{t|t-1} + u_t , \quad t=1,\ldots,T
\end{eqnarray}</p>
<p>where \(y_t\) is a \(n \times 1\) vector of observables, \(s_t\) is a \(m
\times 1\) vector of state variables, \(Z_{t|t-1}\) is an \(n \times m\)
vector, \(d_{t|t-1}\) is a \(n\times 1\) vector, and \(u_t\) are
innovations (or often ``measurement errors&rsquo;&rsquo;) with mean zero and
\(\mathbb{E}_{t-1}[ u_t u_t&rsquo;] = H_{t|t-1}\).
<br></p>
<ul>
<li>The matrices \(Z_{t|t-1}\), \(d_{t|t-1}\), and \(H_{t|t-1}\) are in many applications constant.</li>
<li>However, it is sufficient that they are predetermined at \(t-1\). They could be functions of \(y_{t-1}, y_{t-2}, \ldots\).</li>
<li>To simplify the notation, we will denote them by \(Z_t\), \(d_t\), and \(H_t\), respectively.</li>
</ul>
<h3 id="transition-equation">Transition Equation</h3>
<p>The transition equation is of the form</p>
<p>\begin{eqnarray}
s_t = T_{t|t-1} s_{t-1} + c_{t|t-1} + R_{t|t-1} \eta_t
\end{eqnarray}</p>
<p>where \(R_t\) is \(m \times g\), and \(\eta_t\) is a \(g \times 1\) vector of innovations
with mean zero and variance \(\mathbf{E}_{t|t-1}[ \eta_t \eta_t&rsquo;] = Q_{t|t-1}\).
<br></p>
<ul>
<li>The assumption that \(s_t\) evolves according to an VAR(1) process
is not very restrictive, since it could be the companion form to a
higher order VAR process.</li>
<li>It is furthermore assumed that (i) expectation and variance of the initial state vector are given by \(\mathbf [s_0] = A_0\) and \(var[s_0] = P_0\);</li>
<li>\(u_t\) and \(\eta_t\) are uncorrelated with each other in all time periods , and uncorrelated with the initial state. [not really necessary]</li>
</ul>
<h3 id="adding-it-all-up">Adding it all up</h3>
<p>If the system matrices \(Z_t, d_t, H_t, T_t, c_t, R_t, Q_t\) are non-stochastic
and predetermined, then the system is linear and \(y_t\) can be expressed
as a function of present and past \(u_t\)&rsquo;s and \(\eta_t\)&rsquo;s.
<br></p>
<ol>
<li>calculate predictions \(y_t|Y^{t-1}\), where \(Y^{t-1} = [ y_{t-1}, \ldots, y_1]\),</li>
<li>obtain a likelihood function
\[
p(Y^T| \{Z_t, d_t, H_t, T_t, c_t, R_t, Q_t \})
\]</li>
<li>back out a sequence
\[
\left\{ p(s_t |Y^t, \{Z_\tau, d_\tau, H_\tau, T_\tau,
c_\tau, R_\tau, Q_\tau \} ) \right\}
\]</li>
</ol>
<p>The algorithm is called the <em>Kalman Filter</em> and was originally adopted
from the engineering literature.</p>
<h3 id="a-useful-lemma">A Useful Lemma</h3>
<p><em>Let \((x&rsquo;,y&rsquo;)&rsquo;\) be jointly normal with</em>
\[
\mu = \left[ \begin{array}{c} \mu_x \\ \mu_y \end{array} \right]
\quad \mbox{and} \quad
\Sigma = \left[ \begin{array}{cc} \Sigma_{xx} &amp; \Sigma_{xy} \\
\Sigma_{yx} &amp; \Sigma_{yy} \end{array} \right]
\]
Then the \(pdf(x|y)\) is multivariate normal with</p>
<p>\begin{eqnarray}
\mu_{x|y} &amp;=&amp; \mu_x + \Sigma_{xy} \Sigma_{yy}^{-1}(y - \mu_y) \\
\Sigma_{xx|y} &amp;=&amp; \Sigma_{xx} - \Sigma_{xy} \Sigma_{yy}^{-1} \Sigma_{yx}
\end{eqnarray}</p>
<p>\(\Box\)</p>
<h3 id="a-bayesian-interpretation-to-the-kalman-filter">A Bayesian Interpretation to the Kalman Filter</h3>
<ul>
<li>Although the idea of the algorithm is based on linear projections,
it has a very straightforward Bayesian interpretation.</li>
<li>We will assume that the conditional distributions of \(s_t\) and \(y_t\) given time \(t-1\) information are Gaussian.</li>
<li>Since the system is linear, all the conditional and marginal distributions that we calculate when we move from period \(t-1\) to period \(t\) will also be Gaussian.</li>
<li>Since the state vector \(s_t\) is unobservable, it is natural in Bayesian framework to regard it as a random vector.</li>
</ul>
 <br>
**Note:** The subsequent analysis is conditional on the system
matrices \\(Z\_t, d\_t, H\_t, T\_t, c\_t, R\_t, Q\_t\\).  For notational
convenience we will, however, drop the system matrices from the
conditioning set.
<h3 id="d41d8c"></h3>
<p>The calculations will be based on the following conditional distribution, represented by densities:</p>
<ol>
<li>
<p><strong>Initialization</strong>: \(p(s_{t-1}|Y^{t-1})\)</p>
</li>
<li>
<p><strong>Forecasting</strong>:</p>
<p>\begin{eqnarray*}
p(s_t|Y^{t-1}) &amp;=&amp; \int p(s_t|s_{t-1}, Y^{t-1} ) p(s_{t-1}|Y^{t-1}) ds_{t-1} \\
p(y_t|Y^{t-1}) &amp; = &amp; \int p(y_t | s_t, Y^{t-1} ) p(s_t|Y^{t-1}) d s_t
\end{eqnarray*}</p>
</li>
<li>
<p><strong>Updating</strong>:
\[
p(s_t|Y^t) = \frac{ p(y_t|s_t, Y^{t-1} ) p(s_t|Y_{t-1}) }{ p(y_t|Y^{t-1} )}
\]</p>
</li>
</ol>
<!--listend-->
<ul>
<li>The integrals look troublesome.</li>
<li>However, since the state space model is linear, and the
distribution of the innovations \(u_t\) and \(\eta_t\) are Gaussian
\(\implies\) everything is Gaussian!</li>
<li>Hence, we only have to keep track of conditional means and
variances.</li>
</ul>
<h3 id="initialization">Initialization</h3>
<ul>
<li>In period zero, we will start with a prior distribution for the initial state \(s_0\).
<br></li>
<li>This prior is of the form \(s_0 \sim {\cal N}(A_0,P_0)\).
<br></li>
<li>If the system matrices imply that the state vector has a stationary distribution, we could choose \(A_0\) and \(P_0\) to be the mean and variance of this stationary distribution.</li>
</ul>
<h3 id="forecasting">Forecasting</h3>
<ul>
<li>At \((t-1)^+\), that is, after observing \(y_{t-1}\), the belief
about the state vector has the form \(s_{t-1}|Y^{t-1} \sim {\calN}(A_{t-1}, P_{t-1})\).
<br></li>
<li>Thus, the ``posterior&rsquo;&rsquo; from period \(t-1\) turns into a prior for \((t-1)^+\).
<br></li>
</ul>
<p>Since \(s_{t-1}\) and \(\eta_t\) are independent multivariate normal random
variables, it follows that</p>
<p>\begin{eqnarray}
s_t |Y^{t-1} \sim {\cal N}( \hat{s}_{t|t-1}, P_{t|t-1})
\end{eqnarray}</p>
<p>where</p>
<p>\begin{eqnarray*}
\hat{s}_{t|t-1} &amp; = &amp; T_t A_{t-1} + c_t \\
P_{t|t-1} &amp; = &amp; T_t P_{t-1} T_t&rsquo; + R_t Q_t R_t'
\end{eqnarray*}</p>
<h3 id="forecasting-y-t">Forecasting \(y_t\)</h3>
<p>The conditional distribution of \(y_t|s_t, Y^{t-1}\) is of the form</p>
<p>\begin{eqnarray}
y_t|s_t, Y^{t-1} \sim {\cal N}(Z_t s_t + d_t, H_t)
\end{eqnarray}</p>
<p>Since \(s_t|Y^{t-1} \sim {\cal N}( \hat{s}_{t|t-1}, P_{t|t-1})\), we
can deduce that the marginal distribution of \(y_t\) conditional on \(Y^{t-1}\)
is of the form</p>
<p>\begin{eqnarray}
y_t | Y_{t-1} \sim {\cal N} (\hat{y}_{t|t-1}, F_{t|t-1})
\end{eqnarray}</p>
<p>where</p>
<p>\begin{eqnarray*}
\hat{y}_{t|t-1} &amp; = &amp; Z_t \hat{s}_{t|t-1} + d_t \\
F_{t|t-1} &amp; = &amp; Z_t P_{t|t-1} Z_t&rsquo; + H_t
\end{eqnarray*}</p>
<h3 id="updating">Updating</h3>
<p>To obtain the posterior distribution of \(s_t | y_t, Y^{t-1}\) note that</p>
<p>\begin{eqnarray}
s_t &amp; = &amp; \hat{s}_{t|t-1} + (s_t - \hat{s}_{t|t-1}) \\
y_t      &amp; = &amp; Z_t \hat{s}_{t|t-1} + d_t + Z_t(s_t - \hat{s}_{t|t-1}) + u_t
\end{eqnarray}</p>
<p>and the joint distribution of \(s_t\) and \(y_t\) is given by</p>
<p>\begin{eqnarray}
\left[ \begin{array}{c} s_t \\ x_t \end{array} \right] \Big| Y^{t-1}
\sim
{\cal N} \left(
\left[ \begin{array}{c} \hat{s}_{t|t-1} \\ \hat{y}_{t|t-1} \end{array} \right],
\left[ \begin{array}{cc} P_{t|t-1} &amp; P_{t|t-1} Z_t&rsquo; \\
Z_t P_{t|t-1}&rsquo; &amp; F_{t|t-1}
\end{array} \right]
\right)
\end{eqnarray}</p>
<p>\begin{eqnarray}
s_t | y_t , Y^{t-1} \sim {\cal N}(A_t, P_t)
\end{eqnarray}</p>
<p>where</p>
<p>\begin{eqnarray*}
A_t &amp; = &amp; \hat{s}_{t|t-1} + P_{t|t-1}Z_t&rsquo;F_{t|t-1}^{-1}(y_t - Z_t\hat{s}_{t|t-1} - d_t)\\
P_t &amp; = &amp; P_{t|t-1} - P_{t|t-1} Z_t&rsquo;F_{t|t-1}^{-1}Z_tP_{t|t-1} \\
\end{eqnarray*}</p>
<p>The conditional mean and variance \(\hat{y}_{t|t-1}\) and \(F_{t|t-1}\) were given
above. This completes one iteration of the algorithm. The posterior \(s_t|Y^t\)
will serve as prior for the next iteration. \(\Box\)</p>
<h3 id="likelihood-function">Likelihood Function</h3>
<p>We can define the one-step ahead forecast error</p>
<p>\begin{eqnarray}
\nu_t = y_t - \hat{y}_{t|t-1} =  Z_t (s_t - \hat{s}_{t|t-1}) + u_t
\end{eqnarray}</p>
<p>The likelihood function is given by</p>
<p>\begin{eqnarray}
p(Y^T | \mbox{parameters} )
&amp; = &amp; \prod_{t=1}^T p(y_t|Y^{t-1}, \mbox{parameters}) \nonumber \\
&amp; = &amp; ( 2 \pi)^{-nT/2} \left( \prod_{t=1}^T |F_{t|t-1}| \right)^{-1/2} \nonumber \\
&amp; ~ &amp; \times \exp \left\{ - \frac{1}{2} \sum_{t=1}^T \nu_t F_{t|t-1} \nu_t&rsquo; \right\}
\end{eqnarray}</p>
<p>This representation of the likelihood function is often called prediction
error form, because it is based on the recursive prediction one-step ahead
prediction errors \(\nu_t\). \(\Box\)</p>
<h3 id="multistep-forecasting">Multistep Forecasting</h3>
<p>The Kalman Filter can also be used to obtain multi-step ahead forecasts.
For simplicity, suppose that the system matrices are constant over time.
Since</p>
<p>\begin{eqnarray}
s_{t+h-1|t-1} = T^h s_{t-1} + \sum_{s=0}^{h-1} T^s c
+ \sum_{s=0}^{h-1} T^s R \eta_t
\end{eqnarray}</p>
<p>it follows that</p>
<p>\begin{eqnarray*}
\hat{s}_{t+h-1|t-1} &amp;=&amp; \EE[s_{t+h-1|t-1}|Y^{t-1} ]  =  T^h A_{t-1} + \sum_{s=0}^{h-1} T^s c \\
P_{t+h-1|t-1} &amp; = &amp;   var[s_{t+h-1|t-1}|Y^{t-1} ]  = T^hP_{t-1}T^h + \sum_{s=0}^{h-1} T^s RQR&rsquo;T^{s&rsquo;}
\end{eqnarray*}</p>
<p>which leads to</p>
<p>\begin{eqnarray}
y_{t+h-1} | Y_{t-1} \sim {\cal N} (\hat{y}_{t+h-1|t-1}, F_{t+h-1|t-1})
\end{eqnarray}</p>
<p>where</p>
<p>\begin{eqnarray*}
\hat{y}_{t+h-1|t-1} &amp; = &amp; Z \hat{s}_{t+h-1|t-1} + d \\
F_{t+h-1|t-1} &amp; = &amp; Z P_{t+h-1|t-1} Z&rsquo; + H
\end{eqnarray*}</p>
<p>The multi-step forecast can be computed recursively, simply by omitting the
updating step in the algorithm described above. \(\Box\)</p>
<h3 id="example-1-new-keynesian-dsge">Example 1: New Keynesian DSGE</h3>
<ul>
<li>We can solve the New Keynesian DSGE model described earlier.
<br></li>
<li>Obtain state space representation</li>
</ul>
<h3 id="observables">Observables</h3>
<p>\includegraphics[width=4in]{dsge1_observables}</p>
<h3 id="impulse-responses">Impulse Responses</h3>
<p>\begin{center}
\includegraphics[width=3.5in]{dsge1_all_irf}
\end{center}</p>
<h3 id="filtered-technology-shock--mean">Filtered Technology Shock (Mean)</h3>
<p>\begin{center}
\includegraphics[width=3.5in]{filtered_technology_shock}
\end{center}</p>
<h3 id="log-likelihood-increments">Log Likelihood Increments</h3>
<p>\begin{center}
\includegraphics[width=3.5in]{log_lik}
\end{center}</p>
<h3 id="forecast-of-output-growth">Forecast of Output Growth</h3>
<p>\begin{center}
\includegraphics[width=3.5in]{ygr_forecast}
\end{center}</p>
<h3 id="forecast-of-inflation">Forecast of Inflation</h3>
<p>\begin{center}
\includegraphics[width=3.5in]{infl_forecast}
\end{center}</p>
<h3 id="forecast-of-interest-rate">Forecast of Interest Rate</h3>
<p>\begin{center}
\includegraphics[width=3.5in]{int_forecast}
\end{center}</p>
<h3 id="example-2-arma-models">Example 2 &ndash; ARMA models</h3>
<p>Consider the ARMA(1,1) model of the form</p>
<p>\begin{eqnarray}
y_t = \phi y_{t-1} + \epsilon_t + \theta \epsilon_{t-1} \quad \epsilon_t \sim iid{\cal N}(0,\sigma^2)
\end{eqnarray}</p>
<p>The model can be rewritten in state space form</p>
<p>\begin{eqnarray}
y_t &amp; = &amp; [ 1 \; \theta] \left[ \begin{array}{c} \epsilon_t \\ \epsilon_{t-1} \end{array} \right] + \phi y_{t-1}\\
\left[ \begin{array}{c} \epsilon_t \\ \epsilon_{t-1} \end{array} \right]
&amp; = &amp;
\left[ \begin{array}{cc} 0 &amp; 0 \\ 1 &amp; 0 \end{array} \right]
\left[ \begin{array}{c} \epsilon_{t-1} \\ \epsilon_{t-2} \end{array} \right]
+
\left[ \begin{array}{c} \eta_t \\ 0 \end{array} \right]
\end{eqnarray}</p>
<p>where \(\eta_t \sim iid{\cal N}(0,\sigma^2)\). Thus, the state vector is composed
of \(\alpha_t = [\epsilon_t, \epsilon_{t-1}]&rsquo;\) and \(d_{t|t-1} = \rho y_{t-1}\).
The Kalman filter can be used to
compute the likelihood function of the ARMA model conditional on the
parameters \(\phi, \theta, \sigma^2\). A numerical optimization routine has to
be used to find the maximum of the likelihood function. \(\Box\)</p>
<h3 id="a-model-with-time-varying-coefficients">A Model with Time Varying Coefficients</h3>
<p>Consider the following regression model with time varying coefficients</p>
<p>\begin{eqnarray}
y_t &amp; = &amp; x_t&rsquo; \beta_t + u_t \\
\beta_t &amp; = &amp; T \beta_{t-1} + c + \eta_t
\end{eqnarray}</p>
<p>There are many reasons to believe that macroeconomic relationships are
not stable over time. An entire branch of the econometrics literature
is devoted to tests for structural breaks, that is, tests for changes
in the parameter values. However, to be able to predict future changes
in the parameter values it is important to model the time variation in
the parameters. The state variable \(\alpha_t\) corresponds now to the
vector of regression parameters \(\beta_t\). It is often assumed that
the regression coefficients follow univariate random walks of the form</p>
<p>\begin{eqnarray}
\beta_{j,t} = \beta_{j,t-1} + \eta_{j,t}
\end{eqnarray}</p>
<p>Hence, the only unknown parameters are \(var[u_t]\) and \(var[\eta_{j,t}]\).
The Kalman filter can provide us with a sequence of estimates
for the time varying coefficients.
\[
\{ \EE[\beta_t|Y^t,X^t] \}_{t=1}^T, \quad \{ var[\beta_t|Y^t,X^t] \}_{t=1}^T
\]
and the likelihood of the data conditional on \(\mathbf E[u_t u_t&rsquo;]\), \(\mathbf E[\eta_t \eta_t&rsquo;]\),
\(T\) and \(c\). \(\Box\)</p>
<h2 id="bibliography">Bibliography</h2>
<h3 id="references">References</h3>
<h2 id="references-1">References</h2>
<style>.csl-entry{text-indent: -1.5em; margin-left: 1.5em;}</style><div class="csl-bib-body">
  <div class="csl-entry"><a id="citeproc_bib_item_1"></a><span style="font-variant:small-caps;">An, S., and F. Schorfheide</span>. (2007): <a href="https://doi.org/10.1080/07474930701220071">“Bayesian Analysis of Dsge Models,</a>” <i>Econometric Reviews</i>, 26, 113–72.</div>
  <div class="csl-entry"><a id="citeproc_bib_item_2"></a><span style="font-variant:small-caps;">Christiano, L. J., M. Eichenbaum, and C. L. Evans</span>. (2005): “Nominal Rigidities and the Dynamic Effects of a Shock to Monetary Policy,” <i>Journal of Political Economy</i>, 113, 1–45.</div>
  <div class="csl-entry"><a id="citeproc_bib_item_3"></a><span style="font-variant:small-caps;">Fernandez-Villaverde, J., J. Rubio-Ramirez, and F. Schorfheide</span>. (2016): <a href="https://doi.org/10.1016/bs.hesmac.2016.03.006">“Solution and Estimation Methods for Dsge Models,</a>” <i>Handbook of Macroeconomics</i>, , 527 724.</div>
  <div class="csl-entry"><a id="citeproc_bib_item_4"></a><span style="font-variant:small-caps;">Galí, J.</span> (2008): <i><a href="https://press.princeton.edu/titles/10495.html">Monetary Policy, Inflation, and the Business Cycle: An Introduction to the New Keynesian Framework</a></i>, 2nd ed.Princeton University Press.</div>
  <div class="csl-entry"><a id="citeproc_bib_item_5"></a><span style="font-variant:small-caps;">Hamilton, J.</span> (1994): <i>Time Series Analysis</i>, Princeton, New Jersey: Princeton University Press.</div>
  <div class="csl-entry"><a id="citeproc_bib_item_6"></a><span style="font-variant:small-caps;">Harvey, A. C.</span> (1991): <i>Forecasting, Structural Time Series Models and the Kalman Filter</i>, Cambridge, United Kingdom: University of Cambridge Press.</div>
  <div class="csl-entry"><a id="citeproc_bib_item_7"></a><span style="font-variant:small-caps;">Herbst, E., and F. Schorfheide</span>. (2015): <i>Bayesian Estimation of Dsge Models</i>, Princeton: Princeton University Press.</div>
  <div class="csl-entry"><a id="citeproc_bib_item_8"></a><span style="font-variant:small-caps;">Ireland, P. N.</span> (2004): “A Method for Taking Models to the Data,” <i>Journal of Economic Dynamics and Control</i>, 28, 1205–26.</div>
  <div class="csl-entry"><a id="citeproc_bib_item_9"></a><span style="font-variant:small-caps;">Sims, C. A.</span> (2002): “Solving Linear Rational Expectations Models,” <i>Computational Economics</i>, 20, 1–20.</div>
  <div class="csl-entry"><a id="citeproc_bib_item_10"></a><span style="font-variant:small-caps;">Smets, F., and R. Wouters</span>. (2007): “Shocks and Frictions in Us Business Cycles: A Bayesian Dsge Approach,” <i>American Economic Review</i>, 97, 586–608.</div>
  <div class="csl-entry"><a id="citeproc_bib_item_11"></a><span style="font-variant:small-caps;">Woodford, M.</span> (2003): <i>Interest and Prices</i>, Princeton University Press.</div>
</div>



<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  TeX: { equationNumbers: { autoNumber: "AMS" },
         extensions: ["AMSmath.js", "AMSsymbols.js"] },
  tex2jax: {
      inlineMath: [['$','$'],['\\(','\\)']],
      displayMath: [['$$','$$'], ['\\[', '\\]']],
    processEscapes: true,
    processEnvironments: true,
    skipTags: ['script', 'noscript', 'style', 'textarea', 'pre']
  }
});
</script>
<script type="text/javascript"
  src="//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>


        <div class="footer">
    Powered by <a href="https://gohugo.io/">Hugo</a> with
    <a href="https://github.com/mrmierzejewski/hugo-theme-console/">Console Theme</a>. 
</div>

    </div>
  </body>
</html>
