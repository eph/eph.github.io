<!DOCTYPE html>
<html lang="en-us">
<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <title>Ed Herbst/teaching/bank-of-colombia-smc/notes/kalman-filter/</title>
    
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="robots" content="all,follow">
    <meta name="googlebot" content="index,follow,snippet,archive">
    <link rel="stylesheet" href="https://edherbst.net/hugo-theme-console/css/terminal-0.7.1.min.css">
    <link rel="stylesheet" href="https://edherbst.net/hugo-theme-console/css/animate-3.7.2.min.css">
    <link rel="stylesheet" href="https://edherbst.net/hugo-theme-console/css/console.css">
    
      <!--[if lt IE 9]>
          <script src="https://oss.maxcdn.com/html5shiv/3.7.2/html5shiv.min.js"></script>
          <script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
      <![endif]-->
       <meta property="og:title" content="Some Notes on the Kalman Filter" />
<meta property="og:description" content="" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://edherbst.net/teaching/bank-of-colombia-smc/notes/kalman-filter/" /><meta property="article:published_time" content="2020-12-11T00:00:00+00:00" />



<meta name="twitter:title" content="Some Notes on the Kalman Filter"/>
<meta name="twitter:description" content="State space models form a very general class of models that encompass many of the specifications that we encountered earlier. VARMA models, linearized DSGE models, and more can be written in state space form. State space models are particularly popular at the FRB. For example, the models in the \(r^*\) suite can all be written in state space form.
A state space model can be described by two different equations: a measurement equation that relates an unobservable state vector \(s_t\) to the observables \(y_t\), and a transition equation that describes the evolution of the state vector \(s_t\)."/>

</head>
<body class="terminal">
    <div class="container">
        <div class="terminal-nav">
          <header class="terminal-logo">
            <div class="logo terminal-prompt">
              
              
              
              <a href='https://edherbst.net/teaching'>teaching</a>/<a href='https://edherbst.net/teaching/bank-of-colombia-smc'>bank-of-colombia-smc</a>/<a href='https://edherbst.net/teaching/bank-of-colombia-smc/notes'>notes</a>/<a href='https://edherbst.net/teaching/bank-of-colombia-smc/notes/kalman-filter'>kalman-filter</a>/</div></header>
          <nav class="terminal-menu">
            <ul vocab="https://schema.org/" typeof="BreadcrumbList">
                
                <li><a href="https://edherbst.net/" typeof="ListItem">&lt;/&gt;</a></li>
                
                <li><a href="https://edherbst.net/research/" typeof="ListItem">research</a></li>
                
                <li><a href="https://edherbst.net/teaching/" typeof="ListItem">teaching</a></li>
                
                <li><a href="https://edherbst.net/etc/" typeof="ListItem">et cetera</a></li>
                
            </ul>
          </nav>
        </div>
    </div>

    <div class="container animated zoomIn fast">
        
<h1>Some Notes on the Kalman Filter</h1>
<p>State space models form a very general class of models that encompass
many of the specifications that we encountered earlier.  VARMA models,
linearized DSGE models, and more can be written in state space form.
State space models are particularly popular at the FRB.  For example,
the models in the \(r^*\) suite can all be written in state space form.</p>
<p>A state space model can be described by two different equations: a
measurement equation that relates an <em>unobservable</em> state vector \(s_t\)
to the <em>observables</em> \(y_t\), and a transition equation that describes
the evolution of the state vector \(s_t\).  For now, we&rsquo;ll restrict
attention to the case in which both of these equations are linear.</p>
<p><strong>Measurement.</strong> The measurement equation is of the form</p>
<p>\begin{eqnarray}
\label{eq:obs}
y_t = D_{t|t-1} + Z_{t|t-1} s_t  + \eta_t , \quad t=1,\ldots,T
\end{eqnarray}</p>
<p>where \(y_t\) is an \(n_y \times 1\) vector of observables, \(s_t\) is an \(n_s
\times 1\) vector of state variables, \(Z_{t|t-1}\) is an \(n_y \times n_s\)
vector, \(D_{t|t-1}\) is a \(n_y\times 1\) vector, and \(\eta_t\) are
innovations (or often ``measurement errors&rsquo;&rsquo;) with mean zero and
\(\mathbb{E}_{t-1}[ \eta_t \eta_t&rsquo;] = H_{t|t-1}\).</p>
<ul>
<li>The matrices \(Z_{t|t-1}\), \(D_{t|t-1}\), and \(H_{t|t-1}\) are in many applications constant (&ldquo;time-invariant.&rdquo;)</li>
<li>However, it is sufficient that they are predetermined at \(t-1\). They could be functions of \(y_{t-1}, y_{t-2}, \ldots\).</li>
<li>To simplify the notation, we will denote them by \(Z_t\), \(D_t\), and \(H_t\), respectively.</li>
</ul>
<p><strong>Transition.</strong> The transition equation is of the form</p>
<p>\begin{eqnarray}
\label{eq:transition}
s_t = C_{t|t-1} + T_{t|t-1} s_{t-1}  + R_{t|t-1} \epsilon_t
\end{eqnarray}</p>
<p>where \(R_t\) is \(n_s \times n_\epsilon\), and \(\epsilon\) is a \(n_\epsilon \times 1\) vector of innovations
with mean zero and variance \(\mathbb{E}_{t|t-1}[ \epsilon_t \epsilon_t&rsquo;] = Q_{t|t-1}\).</p>
<ul>
<li>The assumption that \(s_t\) evolves according to an VAR(1) process
is not very restrictive, since it could be the companion form to a
higher order VAR process.</li>
<li>It is furthermore assumed that (i) expectation and variance of the
initial state vector are given by \(\mathbb E[s_0] = A_0\) and
\(\mathbb V[s_0] = P_0\);</li>
<li>\(\eta_t\) and \(\epsilon_t\) are uncorrelated with each other in all
time periods , and uncorrelated with the initial state. This
assumption is not really necessary, but it simplies things
considerable.</li>
</ul>
<p>The collection of matrices in (<a href="#eq:obs">eq:obs</a>) and (<a href="#eq:transition">eq:transition</a>)
define the state space system.  For that reason, they are often
referred to as the &ldquo;system matrices.&rdquo;</p>
<p><em>Example.</em> Consider the ARMA(1,1) model of the form</p>
<p>\begin{eqnarray}
y_t = \phi y_{t-1} + \epsilon_t + \theta \epsilon_{t-1} \quad \epsilon_t \sim iid{\cal N}(0,\sigma^2)
\end{eqnarray}</p>
<p>The model can be rewritten in state space form</p>
<p>\begin{eqnarray}
y_t &amp; = &amp; [ 1 ; \theta] \left[ \begin{array}{c} \epsilon_t \ \epsilon_{t-1} \end{array} \right] + \phi y_{t-1}\\\
\left[ \begin{array}{c} \epsilon_t \ \epsilon_{t-1} \end{array} \right]
&amp; = &amp;
\left[ \begin{array}{cc} 0 &amp; 0 \ 1 &amp; 0 \end{array} \right]
\left[ \begin{array}{c} \epsilon_{t-1} \ \epsilon_{t-2} \end{array} \right]
+
\left[ \begin{array}{c} \eta_t \ 0 \end{array} \right]
\end{eqnarray}</p>
<p>where \(\epsilon_t \sim iid{\cal N}(0,\sigma^2)\). Thus, the state
vector is composed of \(s_t = [\epsilon_t, \epsilon_{t-1}]&rsquo;\) and \(D_{t}
= \rho y_{t-1}\).  This construction is not unique. We could also write
the model as:</p>
<p>\begin{eqnarray}
y_t &amp; = &amp; [ 1 ; 0] \left[ \begin{array}{c} y_t \ \epsilon_{t} \end{array} \right] \\\
\left[ \begin{array}{c} y_t \ \epsilon_{t} \end{array} \right]
&amp; = &amp;
\left[ \begin{array}{cc} \phi &amp; \theta \ 0 &amp; 0 \end{array} \right]
\left[ \begin{array}{c} y_{t-1} \ \epsilon_{t-1} \end{array} \right]
+
\left[ \begin{array}{c} 1\ 1 \end{array} \right]\epsilon_t.
\end{eqnarray}</p>
<p>Notice in this formulation the state vector \(s_t = [y_t,\epsilon_t]\)
is partially observed.  So it&rsquo;s not true, strictly speaking, that the
entire \(s_t\) vector must be unobserved. \(\Box\)</p>
<p>If the system matrices \(D_t, Z_t, H_t, C_t, T_t, R_t, Q_t\) are
non-stochastic and predetermined, then the system is linear and \(y_t\)
can be expressed as a function of present and past \(\eta_t\)&rsquo;s and
\(\epsilon_t\)&rsquo;s.  We&rsquo;ve done some work on linear systems previously
(VARs), so the natural next step is to expand our toolkit to do the
kinds of things we liked to do with VARs:</p>
<ul>
<li>
<p>Calculate predictions \(y_t|Y^{t-1}\), where \(Y^{t-1} = [ y_{t-1}, \ldots, y_1]\),</p>
</li>
<li>
<p>Obtain a likelihood function</p>
<p>\begin{eqnarray}
\label{eq:likelihood}
p(Y^T| \{Z_t, D_t, H_t, T_t, C_t, R_t, Q_t \}),
\end{eqnarray}</p>
</li>
<li>
<p>and, <em>something we didn&rsquo;t do with VARs</em>, back out a sequence
\[
\left\{ p(s_t |Y^t, \{Z_t, D_t, H_t, T_t,
C_t, R_t, Q_t \} ) \right\}_{t=1}^T.
\]</p>
</li>
</ul>
<p>Now, if the state vector was observed, it would be easy to combine
equation (<a href="#eq:obs">eq:obs</a>) and (<a href="#eq:transition">eq:transition</a>) to obtain a VAR jointly
in \([y_t, s_t]\).  Thus, it would be straightforward to obtain the
(perhaps conditional) likelihood:
\[
p(Y^T,S^T | \{Z_t, D_t, H_t, T_t, C_t, R_t, Q_t \}).
\]
But life is hard, and we don&rsquo;t get to observe \(S^T\).  We need to
compute the likelihood for the data we have, i.e., the likelihood in
(<a href="#eq:likelihood">eq:likelihood</a>).  We have to marginalize out \(S^T\).  It turns out
that their is an algorithm that does this, and fulfills the three
desiderata above.  The algorithm is called the <em>Kalman Filter</em> and was
originally adopted from the engineering literature.</p>
<h2 id="the-kalman-filter">The Kalman Filter</h2>
<p>For this presentation of the Kalman filter, we&rsquo;re going to assume
that the system matrices are time invariant, that is, they do not
depend on \(t\).  So we drop these subscripts from our notation.
Furthermore, we&rsquo;re going to collect them in the vector \(\theta =
[C,T,R,Q,D,Z,H]\), where the \(vec\) operator is being implicitly
applied to each matrix.</p>
<p>We&rsquo;re also going to assume that the innovations \(\eta_t\) and
\(\epsilon_t\) are normally distributed.  We need to this to obtain
an exact likelihood, although the Kalman filter can
be used to obtain an optimal&mdash;in terms of MSE&mdash;predictor \(y_{t+h}\)
given \(Y^T\) for \(h \ge 1\) using linear projections, regardless of
the parametric distributions for \(\eta_t\) and \(\epsilon_t\).  The
chapter on state space models in <sup id="adec714ae69bef54c5ee79cfcb41955d"><a href="#Hamilton" title="James Hamilton, Time Series Analysis, Princeton University Press (1994).">Hamilton</a></sup> derives this. In
this case the likelihood calculation delivers a quasi-likelihood.</p>
<p>With our normality assumption, the derivation of the Kalman filter
has a natural Bayesian interpretation.  Before we proceed, we&rsquo;re
going to state some results about multivariate normal
distributions, which will help later on.</p>
<p><em>Lemma.</em> Let \((x&rsquo;,y&rsquo;)&rsquo;\) be jointly normal with
\[
\mu = \left[ \begin{array}{c} \mu_x \ \mu_y \end{array} \right]
\quad \mbox{and} \quad
\Sigma = \left[ \begin{array}{cc} \Sigma_{xx} &amp; \Sigma_{xy} \\\
\Sigma_{yx} &amp; \Sigma_{yy} \end{array} \right]
\]
Then the \(pdf(x|y)\) is multivariate normal with</p>
<p>\begin{eqnarray}
\mu_{x|y} &amp;=&amp; \mu_x + \Sigma_{xy} \Sigma_{yy}^{-1}(y - \mu_y) \\\
\Sigma_{xx|y} &amp;=&amp; \Sigma_{xx} - \Sigma_{xy} \Sigma_{yy}^{-1} \Sigma_{yx}
\end{eqnarray}</p>
<p>Note that the converse is not necessarily true. \(\Box\)</p>
<p>In both theory and practice, the Kalman filter proceeds
recursively, using the natural prior-posterior sequencing, after an
initialization.</p>
<p><em>Initialization.</em> We&rsquo;re going to start at period \(t=0\), that is,
the period before we first observe \(y\).  We assume that \(s_0\) is
normally distributed:</p>
<p>\begin{align}
s_0 | \theta \sim \mathcal N\left(A_0, P_0\right).
\end{align}</p>
<p>Importantly, we conceptualize this distribution as prior
distribution.  We&rsquo;ll discuss possible ways to select \(A_0\) and
\(P_0\) in a bit.</p>
<p><em>Prediction.</em> We can combine our prior distribution for \(s_0\) with
the state transition equation (<a href="#eq:transition">eq:transition</a>).  Since \(s_0\) is
normally distributed and \(\epsilon_1\) is also normally distributed
(and independent of \(s_0\)), \(s_1\) is also normally distributed,
\[
s_1 | \theta \sim \mathcal N\left(A_{1|0}, P_{1|0}\right)
\]
where
\[
A_{1|0} = C+T A_{0} \mbox{ and } P_{1|0} = T P_0 T&rsquo; + RQR&rsquo;.
\]
Note that this is the unconditional distribution of \(s_1\), a prior
distribution for \(s_1\) before seeing \(y_1\).  We write the mean
\(A_{1|0}\) and \(P_{1|0}\) as conditional on time \(t=0\).</p>
<p>Next consider the prediction of \(y_1\).  The conditional
distribution of \(y_1\) is of the form</p>
<p>\begin{eqnarray}
y_1|s_1,\theta  \sim {\cal N}(D+Z s_1, H)
\end{eqnarray}</p>
<p>Since \(s_1 \sim {\cal N}( A_{1|0}, P_{1|0})\), we can deduce that
the marginal distribution of \(y_1\) is of the form</p>
<p>\begin{eqnarray}
y_1|\theta  \sim {\cal N} (\hat{y}_{1|0}, F_{1|0})
\end{eqnarray}</p>
<p>where</p>
<p>\begin{eqnarray*}
\hat{y}_{1|0} = D + Z A_{1|0} \mbox{ and }  F_{1|0} =  Z P_{1|0} Z&rsquo; + H.
\end{eqnarray*}</p>
<p>Here we&rsquo;ve been explicit in going \(s_0 \rightarrow s_1 \rightarrow
y_1\).</p>
<p><em>Updating.</em> Another way to see this is to rewrite the
observation equation (<a href="#eq:obs">eq:obs</a>) in terms of \(s_{t-1}\) and
\(\epsilon_t\).  If \(s_{0}\) is normally distributed as above it&rsquo;s
easy to see that \(s_1\) and \(y_1\) are jointly normally distributed with
the marginal and conditional distributions mentioned above.  We have:</p>
<p>\begin{eqnarray}
s_1 &amp;=&amp; C + T s_0 + R\epsilon_t \\\
y_1 &amp;=&amp; D + Z T s_0 + Z\epsilon_t + \eta_t.
\end{eqnarray}</p>
<p>Direct calculation yields:</p>
<p>\begin{eqnarray}
\begin{bmatrix}s_1 \ y_1 \end{bmatrix} \bigg| \theta \sim \mathcal N \left( \begin{bmatrix} A_{1|0} \ \hat y_{1|0} \end{bmatrix}, \begin{bmatrix} P_{1|0} &amp; P_{1|0} Z&rsquo; \ Z P_{1|0} &amp; F_{1|0} \end{bmatrix}\right).
\end{eqnarray}</p>
<p>Consider the third goal of toolbox: delivering
\(p(s_1|y_1,\theta)\). Well, we can get that easily using the formula
for the conditional normal distribution:</p>
<p>\begin{align}
\label{eq:update}
s_1 | y_1 \sim N\left( A_{1|0} + P_{1|0} Z&rsquo; F_{1|0}^{-1} \left(y_1 - \hat y_{1|0}\right), P_{1|0} - P_{1|0} Z&rsquo; F_{1|0}^{-1} Z P_{1|0}\right).
\end{align}</p>
<p>Note that we could have instead obtained this using:</p>
<p>\begin{align}
\label{eq:bayes}
p(s_1 | y_1,\theta) \propto p(y_1|s_1,\theta) p(s_1|\theta),
\end{align}</p>
<p>i.e., our good friend Bayes rule!  Note the conjugacy
(normal-normal) likelihood-prior relationship yields a normally
distributed posterior.  Finally, let&rsquo;s call give our updated state mean and variance:</p>
<p>\begin{align}
\label{eq:ms}
A_1 = A_{1|0} + P_{1|0} Z&rsquo; F_{1|0}^{-1} \left(y_1 - \hat y_{1|0}\right) \mbox{ and } P_1 = P_{1|0} - P_{1|0} Z&rsquo; F_{1|0}^{-1} Z P_{1|0}.
\end{align}</p>
<p><em>Generalization.</em> Now, with the distribution form
\(s_1|y_1,\theta\), we&rsquo;re back where we started!  So all we have to
do is construct \(s_2|y_1,\theta\) and \(y_2 | s_2, y_1, \theta\) in an
identical fashion as above, and so on for \(t = 2,\ldots,T\).  We
can summarize the recursions:</p>
<ol>
<li>
<p><strong>Initialization.</strong>  Set \(s_0 \sim N(A_0,P_0).\)</p>
</li>
<li>
<p><strong>Recursions.</strong> For \(t=1,\ldots,T\):</p>
<p>\begin{align}
\label{eq:state-prediction}
\mbox{state prediction}&amp;: A_{t|t-1} = C+T A_{t-1} \mbox{ and } P_{t|t-1} = T P_{t-1} T&rsquo; + RQR&rsquo;.\\\
\label{eq:obs-prediction}
\mbox{observation prediction}&amp;: \hat y_{t|t-1} = D + Z A_{t|t-1} \mbox{ and } F_{t|t-1} = Z P_{t|t-1} Z&rsquo; + H. \\\
\label{eq:state-update}
\mbox{state update}&amp;: A_t = A_{t|t-1} + P_{t|t-1} Z&rsquo; F_{t|t-1}^{-1} \left(y_t - \hat y_{t|t-1}\right) \mbox { and } \nonumber \\\
&amp;~~ P_t = P_{t|t-1} - P_{t|t-1} Z&rsquo; F_{t|t-1}^{-1} Z P_{t|t-1}.
\end{align}</p>
</li>
</ol>
<p><em>Likelihood function.</em> We can define the one-step ahead forecast error</p>
<p>\begin{eqnarray}
\nu_t = y_t - \hat{y}_{t|t-1} =  Z (s_t - A_{t|t-1}) + \eta_t.
\end{eqnarray}</p>
<p>The likelihood function is given by</p>
<p>\begin{eqnarray}
p(Y^T | \theta )
&amp; = &amp; \prod_{t=1}^T p(y_t|Y^{t-1}, \theta) \nonumber \\\
&amp; = &amp; ( 2 \pi)^{-n_yT/2} \left( \prod_{t=1}^T |F_{t|t-1}| \right)^{-1/2} \times \exp \left\{ - \frac{1}{2} \sum_{t=1}^T \nu_t F_{t|t-1}^{-1} \nu_t&rsquo; \right\}
\end{eqnarray}</p>
<p>This representation of the likelihood function is often called prediction
error form, because it is based on the recursive prediction one-step ahead
prediction errors \(\nu_t\). \(\Box\)</p>
<h3 id="discussion">Discussion</h3>
<p><em>Initialization.</em> First, on the initialization step, if the
system-matrices are time-invariant and the process for \(s_t\) is
stationary (i.e., all the eigenvalues of \(T\) are less than one in
magnitude), it might make sense to initialize the Kalman filter
from the invariant distribution, i.e., we have \(A_0\) and \(P_0\) such that
\[
A_0 = (I_{n_s} - T)^{-1} C \mbox{ and } P_0 = T P_0 T&rsquo; + RQR&rsquo;.
\]
If the system is not too big, you can solve for \(P_0\) directly
using the \(vec\) operator:
\[
vec(P_0) = \left(I_{n_s^2} - (T&rsquo; \otimes T)\right)^{-1} RQR&rsquo;.
\]
Otherwise, there are algorithms available for computing \(P_0\)
reliably and quickly.</p>
<p>If the system is not stationary, it&rsquo;s common practice to set the
variance of \(P_0\) be extremely large, like \(1000\times I_{n_s}\).</p>
<p><em>Kalman Gain.</em> In (<a href="#eq:state-update">eq:state-update</a>), the matrix that maps the
prediction errors, \(\nu_t\), into the state revision is important
enough to warrant it&rsquo;s own name: the Kalman Gain.  The Kalman Gain,
\[
K_t = P_{t|t-1} Z F_{t|t-1}^{-1},
\]
is an \(n_s\times n_y\) matrix that maps the &ldquo;surprises&rdquo; (forecast
errors) in the observed data to changes in our beliefs about the
underlying unobserved states.  Essentially, the gain tells us how
we learn about the states from the data.</p>
<p><em>Time-varying system matrices and missing data.</em> The Kalman filter
recursions in (<a href="#eq:state-prediction">eq:state-prediction</a>), (<a href="#eq:obs-prediction">eq:obs-prediction</a>),
and (<a href="#eq:state-update">eq:state-update</a>) are valid if the system matrices are
time-varying (but pre-determined.)  In practice, it is simply a
matter of adding the relevant subscripts onto the system matrices.
An important case of time-varying system matrices is when they are
constant except for the fact that some of the observations are
missing; i.e, for some \(t\), at least one element of \(y_t\) is
missing.  In this case, we simply modify the observation equation
(<a href="#eq:obs">eq:obs</a>)&mdash;and hence, (<a href="#eq:obs-prediction">eq:obs-prediction</a>) and
(<a href="#eq:state-update">eq:state-update</a>)&mdash;in order to account for the fact that we
observe fewer series at some periods.  Suppose in period \(t\) we
observe \(n_{y_t}\), which is less than or equal to \(n_y\).  Define the
\(n_{y_t} \times n_y\) select matrix \(M_t\), to be the matrix whose
columns are comprised of \(\{e_i : i\mbox{th series is
observed}\}\), where \(e_i\) is the \(n_y\times 1\) vector with a
one in the \(i\)th position and zeros elsewhere.  Then,</p>
<p>\begin{align}
\label{eq:missing}
D_t = M_t D,~~ Z_t = M_t Z, \mbox{ and } H_t = M_t H M_t&rsquo;.
\end{align}</p>
<p>The ability to handle missing data is an extremely powerful feature
of the Kalman filter, as it allows us to both handle estimating
models with missing data, and make inference about the missing data
itself.  More on this later.  Most programmed Kalman filter
routines can handle missing data without an modification of the
system matrices on the part of the user.  Simply code your missing
data as <code>nan</code>.  Finally, note that the likelihood calculation in
(<a href="#eq:likelihood">eq:likelihood</a>) needs to be modified (i.e., \(n_y\) needs to be
replaced by \(n_{y_t}\).)  Again, preprogrammed routines should
handle this without user intervention.</p>
<p><em>&ldquo;Steady-state&rdquo; Kalman filter.</em> Suppose the system matrices are constant. If we combine
(<a href="#eq:state-prediction">eq:state-prediction</a>), (<a href="#eq:obs-prediction">eq:obs-prediction</a>) (<a href="#eq:state-update">eq:state-update</a>) for the state
variance, we obtain</p>
<p>\begin{eqnarray}
P_{t+1|t} = T P_{t|t-1}T&rsquo; + RQR - T P_{t|t-1} Z&rsquo; (Z P_{t|t-1} Z&rsquo; + H)^{-1} Z P_{t|t-1}T'
\end{eqnarray}</p>
<p>with \(P_{0|-1} = P_0.\) This equation is known as the <em>matrix
Riccati recursion</em>, a discrete time analogue to the popular set of
ODEs.  Under some regularity conditions, as \(t\) gets sufficiently
large, \(P_{t+1|t} \rightarrow \bar P\), i.e., there is an
invariant solution to the Riccati equation.  Some people refer to
this as the &ldquo;steady-state&rdquo; prediction variance (and
correspondingly, the &ldquo;steady-state&rdquo; Kalman gain.)  It can be useful
in computation as well: after a sufficiently amount of time, one
does not need to continue to update \(P_{t|t-1}\), which is the
typically the costliest part of evaluating the Kalman filter.  Note
this also makes clear that the variances in the Kalman filter to
not depend on the observed data.</p>
<p><em>Caution.</em> Some authors adopt a slightly different timing
convention with the Kalman Filter; specifically,
<sup id="24ddf79004b9c9c124e26e4c2a10a17e"><a href="#DurbinKoopman2001" title="Durbin \&amp; Koopman, Time Series Analysis by State Space Methods, Oxford University Press (2001).">DurbinKoopman2001</a></sup>.  The initialization of the filter changes
slightly.  It&rsquo;s all very tedious.</p>
<h3 id="kalman-smoothing">Kalman Smoothing</h3>
<p>Note that the Kalman filter is a <em>filter</em>: it delivers the
sequence of smoothed distribution \(\{s_t | Y^{t}\}_{t=1}^T\),
which since they are normal, are simply described by the sequence
\(\{A_t,P_t\}_{t=1}^T\).  Sometimes, we interested in the
<em>smoothed</em> distributions, \(\{s_t | Y^T\}_{t=1}^T\), that is
distributions of the unobserved states conditional on all of the
data.  These distributions are also normally distributed, and can
be found another recursive algorithm known as the Kalman smoother.</p>
<p>The Kalman smoother is more or less the Kalman filter in reverse.
Let&rsquo;s define \[ A_{t|T} = \mathbb E[s_{t}|Y^T] \mbox{ and }
P_{t|T} = \mathbb V[S_t|Y^T].  \] The Kalman smoother delivers to
the sequence \(\{A_{t|T},P_{t|T}\}_{t=1}^T\).  Clearly, \(A_{T|T}
= A_T\) and \(P_{T|T} = P_T\).  Consider next computing the
smoothed distribution at time \(T-1\).  Consider the joint
distribution of the form</p>
<p>\begin{eqnarray}
\label{eq:smoother}
\begin{bmatrix}s_{T-1} \ s_T \ y_T \end{bmatrix} \bigg| Y^{T-1}, \theta
\sim \mathcal N \left( \begin{bmatrix} A_{T-1} \ A_{T|T-1} \ \hat y_{T|T-1} \end{bmatrix}, \begin{bmatrix} P_{T-1} &amp; P_{T-1}T&rsquo; &amp; P_{T-1} T&rsquo; Z&rsquo;  \\\
T P_{T-1} &amp; P_{T|T-1} &amp; P_{T|T-1} Z&rsquo; \\\
Z T P_{T-1} &amp; Z P_{T|T-1} &amp; F_{T|T-1} \end{bmatrix}\right).
\end{eqnarray}</p>
<p>Thus, the mean of \(s_{T-1} | Y^T, \theta\) is given by:</p>
<p>\begin{align}
A_{T-1|T} &amp;= A_{T-1} + P_{T-1} T&rsquo; Z&rsquo; F_{T|T-1}^{-1} (y_T - \hat y_{T|T-1})  &amp;  \nonumber \\\
&amp;= A_{T-1} + \underbrace{P_{T-1} T&rsquo; P_{T|T-1}^{-1}}_{J_{T-1}} (A_T - A_{T|T-1}) &amp; \mbox{using (\ref{eq:state-update})}.
\end{align}</p>
<p>The variance is similarly calculated as:</p>
<p>\begin{align}
P_{T-1|T} &amp;= P_{T-1} - P_{T-1} T&rsquo; Z&rsquo; F_{T|T-1}^{-1} Z T P_{T-1} &amp; \nonumber \\\
&amp;= P_{T-1} - J_{T-1}  (P_T - P_{T|T-1}) J_{T-1} &rsquo; &amp; \mbox{using (\ref{eq:state-update})}.
\end{align}</p>
<p>To extend this to \(T-2\) and so on simply modify
(\ref{eq:smoother}).  Note that the procedure sketched here can be
numerically unstable, most packaged software will take care of this.</p>
<h3 id="drawing-from-the-smoothed-distribution">Drawing from the Smoothed Distribution</h3>
<p>Often times one wants to simulate from the smoothed distribution.
Conceptually this is straightforward, but note that our sequence
of smoothed distributions we derived above does not include the
joint distribution of the \(s_t\)s. Drawing from the joint
distribution \(S^T|Y^T\) is known as <em>simulation smoothing</em>.
Doing this quickly and accurately has been a topic of research of
the past few decades.  <sup id="06c4f76f1c94218ef506984466e55826"><a href="#fruhwirth1994data" title="Fr\uhwirth-Schnatter, Data augmentation and dynamic linear models, {Journal of time series analysis}, v(2), 183--202 (1994).">fruhwirth1994data</a></sup> and <sup id="722889c67c6fe32289a84dc9777dce67"><a href="#CaKohn94" title="Carter \&amp; Robert Kohn, On Gibbs Sampling for State Space Models, {Biometrika}, v(3), 541-553 (1994).">CaKohn94</a></sup>
independently developed methods of drawing samples of \(S^T | Y^T\)
using a recursive technique consisting of first sampling \(s_T|Y^T\)
and then sampling \(S_{T-1}| Y^T, s^T\) and so on.  Importance
computational improvements were made first by <sup id="b0f8713f53ddd59bc2bb67804de5c737"><a href="#Jong1995" title="de Jong \&amp; Shephard, The Simulation Smoother for Time Series Models, {Biometrika}, v(2), 339-350 (1995).">Jong1995</a></sup> and
then <sup id="b7c6a391a47d6fb8f1324db49b57ec0f"><a href="#Durbin2002" title="Durbin \&amp; Koopman, A Simple and Efficient Simulation Smoother for State Space Time Series  Analysis, {Biometrika}, v(3), 603-615 (2002).">Durbin2002</a></sup>.</p>
<h2 id="an-example-gdp-plus">An Example: GDP+</h2>
<p>Here I&rsquo;m going to through a simple state space model described in
<sup id="4a8176e7e49ddd5d4c003a31f7a8fe04"><a href="#Aruoba_2016" title="Aruoba, Diebold, , Nalewaik, Schorfheide, Song \&amp; Dongho, Improving GDP measurement: A measurement-error  perspective, {Journal of Econometrics}, v(2), 384 397 (2016).">Aruoba_2016</a></sup>.  Since GDP data is inherently noisy, the authors
use both income-side \((GDP_{It})\) and expenditure-side
\((GDP_{Et})\) data on GDP growth to infer the true (unobserved) growth rate,
\(GDP_t\).  The authors posit that the true growth rate follows an AR(1):</p>
<p>\begin{align}
\label{eq:gdp}
GDP_t = \mu (1-\rho) + \rho GDP_{t-1} + \epsilon_t, \quad \epsilon_t \sim IID N(0, \sigma^2).
\end{align}</p>
<p>An that both income- and expenditure-side estimates are mismeasured versions of this:</p>
<p>\begin{align}
\label{eq:gdp-measure}
\begin{array}{c}
GDP_{Et} \ GDP_{It}
\end{array}
\bigg| GDP_t
\sim IID N \left(
\left[
\begin{array}{c}
GDP_t \ GDP_t
\end{array}
\right],
\left[
\begin{array}{cc}
\sigma_{E}^2 &amp; 0 \ 0 &amp; \sigma_{I}^2
\end{array}
\right]\right)
\end{align}</p>
<p>We can cast this into state space form with \(n_y = 2\) and \(n_s = n_\epsilon = 1\).  We have</p>
<p>\begin{align}
C = \mu(1-\rho),~~ T = \rho,~~ R = 1, \mbox{ and } Q = \sigma^2, \nonumber \\\
D = \begin{bmatrix}0 \ 0 \end{bmatrix}, ~~ Z = \begin{bmatrix}1 \ 1 \end{bmatrix}, \mbox{ and } H =     \left[
\begin{array}{cc}
\sigma_{E}^2 &amp; 0 \ 0 &amp; \sigma_{I}^2
\end{array}
\right].
\end{align}</p>
<p>Here&rsquo;s a look at the data:</p>
<p><img src="https://edherbst.net/ox-hugo/8f8c7ed886ee0fc55dde9d8e51bd3f65cc2ca7fc.png" alt="">
We can use the Kalman filter to maximize the likelihood function,
since we haven&rsquo;t quite worked out how to elicit the posterior of
this model just yet.</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-text" data-lang="text"><span style="display:flex;"><span>Initial likelihood:  -4293.835439078496
</span></span><span style="display:flex;"><span>Maximized Likelihood:  -358.8810028467478
</span></span><span style="display:flex;"><span>{&#39;rho&#39;: 0.5097444850915837, &#39;mu&#39;: 0.39613152196112617, &#39;sige&#39;: 0.2827543510275178, &#39;sigi&#39;: 0.4032653925782693, &#39;sig&#39;: 0.6404475458159359}
</span></span></code></pre></div><p>We these point estimates, we can use the kalman filter to extract
\(\{ A_t\}_{t=1}^T\), the filtered means of the &ldquo;true&rdquo; GDP series.
We&rsquo;ll plot them along with the observables, and the simple average
of expenditure-side and income-side GDP estimates.</p>
<figure><img src="https://edherbst.net/ox-hugo/cb6ce1f5d1fa3c6a180eb701c9ed82c3b28b84cb.png"/>
</figure>

<p>To make it a bit easier to see, let&rsquo;s look at the last five or so years.</p>
<p><img src="https://edherbst.net/ox-hugo/29b3789b20a0fa50d6408b5db6a61177c58f491c.png" alt="">
You can see the average is different form the filtered estimate.
Why is that?  The Kalman Gain matrix places different weights on
the income- and expenditure-side GDP data.</p>
<h1 id="bibliography">Bibliography</h1>
<p><a id="Hamilton"></a>[Hamilton] James Hamilton, Time Series Analysis, Princeton University Press (1994). <a href="#adec714ae69bef54c5ee79cfcb41955d">↩</a></p>
<p><a id="DurbinKoopman2001"></a>[DurbinKoopman2001] Durbin &amp; Koopman, Time Series Analysis by State Space Methods, Oxford University Press (2001). <a href="#24ddf79004b9c9c124e26e4c2a10a17e">↩</a></p>
<p><a id="fruhwirth1994data"></a>[fruhwirth1994data] Fr&quot;uhwirth-Schnatter, Data augmentation and dynamic linear models, <i>Journal of time series analysis</i>, <b>15(2)</b>, 183-202 (1994). <a href="#06c4f76f1c94218ef506984466e55826">↩</a></p>
<p><a id="CaKohn94"></a>[CaKohn94] Carter &amp; Robert Kohn, On Gibbs Sampling for State Space Models, <i>Biometrika</i>, <b>81(3)</b>, 541-553 (1994). <a href="#722889c67c6fe32289a84dc9777dce67">↩</a></p>
<p><a id="Jong1995"></a>[Jong1995] de Jong &amp; Shephard, The Simulation Smoother for Time Series Models, <i>Biometrika</i>, <b>82(2)</b>, 339-350 (1995). <a href="#b0f8713f53ddd59bc2bb67804de5c737">↩</a></p>
<p><a id="Durbin2002"></a>[Durbin2002] Durbin &amp; Koopman, A Simple and Efficient Simulation Smoother for State Space Time Series  Analysis, <i>Biometrika</i>, <b>89(3)</b>, 603-615 (2002). <a href="http://dx.doi.org/10.1093/biomet/89.3.603">doi</a>. <a href="#b7c6a391a47d6fb8f1324db49b57ec0f">↩</a></p>
<p><a id="Aruoba_2016"></a>[Aruoba_2016] Aruoba, Diebold, , Nalewaik, Schorfheide, Song &amp; Dongho, Improving GDP measurement: A measurement-error  perspective, <i>Journal of Econometrics</i>, <b>191(2)</b>, 384 397 (2016). <a href="http://dx.doi.org/10.1016/j.jeconom.2015.12.009">link</a>. <a href="http://dx.doi.org/10.1016/j.jeconom.2015.12.009">doi</a>. <a href="#4a8176e7e49ddd5d4c003a31f7a8fe04">↩</a></p>



<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  TeX: { equationNumbers: { autoNumber: "AMS" },
         extensions: ["AMSmath.js", "AMSsymbols.js"] },
  tex2jax: {
      inlineMath: [['$','$'],['\\(','\\)']],
      displayMath: [['$$','$$'], ['\\[', '\\]']],
    processEscapes: true,
    processEnvironments: true,
    skipTags: ['script', 'noscript', 'style', 'textarea', 'pre']
  }
});
</script>
<script type="text/javascript"
  src="//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>


        <div class="footer">
    Powered by <a href="https://gohugo.io/">Hugo</a> with
    <a href="https://github.com/mrmierzejewski/hugo-theme-console/">Console Theme</a>. 
</div>

    </div>
  </body>
</html>
