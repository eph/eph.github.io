<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Lectures on Ed Herbst</title>
    <link>http://localhost:1313/teaching/bank-of-colombia-smc/lectures/</link>
    <description>Recent content in Lectures on Ed Herbst</description>
    <generator>Hugo</generator>
    <language>en-us</language>
    <lastBuildDate>Fri, 11 Dec 2020 09:47:16 -0500</lastBuildDate>
    <atom:link href="http://localhost:1313/teaching/bank-of-colombia-smc/lectures/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>The Particle Filter</title>
      <link>http://localhost:1313/teaching/bank-of-colombia-smc/lectures/07-nonlinear-dsge-models-and-particle-filters/</link>
      <pubDate>Fri, 11 Dec 2020 09:47:16 -0500</pubDate>
      <guid>http://localhost:1313/teaching/bank-of-colombia-smc/lectures/07-nonlinear-dsge-models-and-particle-filters/</guid>
      <description>&lt;h2 id=&#34;nonlinear-dsge-models&#34;&gt;Nonlinear DSGE Models&lt;/h2&gt;&#xA;&lt;h3 id=&#34;from-linear-to-nonlinear-dsge-models&#34;&gt;From Linear to Nonlinear DSGE Models&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;While DSGE models are inherently nonlinear, the nonlinearities are often&#xA;small and decision rules are approximately linear.&#xA;&lt;br&gt;&lt;/li&gt;&#xA;&lt;li&gt;One can add certain features that generate more pronounced nonlinearities:&#xA;&lt;ul&gt;&#xA;&lt;li&gt;stochastic volatility;&lt;/li&gt;&#xA;&lt;li&gt;markov switching coefficients;&lt;/li&gt;&#xA;&lt;li&gt;asymmetric adjustment costs;&lt;/li&gt;&#xA;&lt;li&gt;occasionally binding constraints.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;from-linear-to-nonlinear-dsge-models&#34;&gt;From Linear to Nonlinear DSGE Models&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;Linear DSGE model leads to&lt;/p&gt;&#xA;&lt;p&gt;\begin{eqnarray*}&#xA;y_t &amp;amp;=&amp;amp; \Psi_0(\theta) + \Psi_1(\theta)t + \Psi_2(\theta) s_t + u_t, \quad u_t \sim N(0,\Sigma_u) ,\\\&#xA;s_t &amp;amp;=&amp;amp; \Phi_1(\theta)s_{t-1} + \Phi_\epsilon(\theta) \epsilon_t, \quad \epsilon_t \sim N(0,\Sigma_\epsilon).&#xA;\end{eqnarray*}&lt;/p&gt;</description>
    </item>
    <item>
      <title>Particle MCMC and SMC^2</title>
      <link>http://localhost:1313/teaching/bank-of-colombia-smc/lectures/08-pmcmc-and-smc-squared/</link>
      <pubDate>Fri, 11 Dec 2020 09:47:02 -0500</pubDate>
      <guid>http://localhost:1313/teaching/bank-of-colombia-smc/lectures/08-pmcmc-and-smc-squared/</guid>
      <description>&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;&#xA;&lt;h3 id=&#34;embedding-pf-likelihoods-into-posterior-samplers&#34;&gt;Embedding PF Likelihoods into Posterior Samplers&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Likelihood functions for nonlinear DSGE models can be approximated by the PF.&#xA;&lt;br&gt;&lt;/li&gt;&#xA;&lt;li&gt;We will now embed the likelihood approximation into a posterior sampler:&#xA;PFMH Algorithm (a special case of PMCMC).&#xA;&lt;br&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;embedding-pf-likelihoods-into-posterior-samplers&#34;&gt;Embedding PF Likelihoods into Posterior Samplers&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Distinguish between:&#xA;&lt;ul&gt;&#xA;&lt;li&gt;\(\{ p(Y|\theta), p(\theta|Y), p(Y) \}\), which are related according to:&#xA;\[&#xA;p(\theta|Y) = \frac{p(Y|\theta) p(\theta)}{p(Y)} , \quad p(Y) = \int p(Y|\theta) p(\theta) d\theta&#xA;\]&lt;/li&gt;&#xA;&lt;li&gt;\(\{ \hat{p}(Y|\theta), \hat{p}(\theta|Y), \hat{p}(Y) \}\), which are related according to:&#xA;\[&#xA;\hat{p}(\theta|Y) = \frac{\hat{p}(Y|\theta) p(\theta)}{\hat{p}(Y)} , \quad \hat{p}(Y) = \int \hat{p}(Y|\theta) p(\theta) d\theta.&#xA;\]&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;Surprising result from &lt;sup id=&#34;bdbeaec8ecb4a8ea982e4ad765654ea6&#34;&gt;&lt;a href=&#34;#Andrieu_2010&#34; title=&#34;Andrieu, Doucet, \&amp;amp; Holenstein, Particle Markov chain Monte Carlo methods, {Journal of the Royal Statistical Society: Series B&#xA;(Statistical Methodology)}, v(3), 269 342 (2010).&#34;&gt;Andrieu_2010&lt;/a&gt;&lt;/sup&gt;: under certain conditions we can replace \(p(Y|\theta)\) by \(\hat{p}(Y|\theta)\) and still obtain draws from \(p(\theta|Y)\).&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;pfmh-algorithm&#34;&gt;PFMH Algorithm&lt;/h3&gt;&#xA;&lt;p&gt;For \(i=1\) to \(N\):&lt;/p&gt;</description>
    </item>
    <item>
      <title>Monte Carlo Simulation</title>
      <link>http://localhost:1313/teaching/bank-of-colombia-smc/lectures/03-monte-carlo-simulation/</link>
      <pubDate>Fri, 11 Dec 2020 09:46:48 -0500</pubDate>
      <guid>http://localhost:1313/teaching/bank-of-colombia-smc/lectures/03-monte-carlo-simulation/</guid>
      <description>&lt;h2 id=&#34;importance-sampling&#34;&gt;Importance Sampling&lt;/h2&gt;&#xA;&lt;h3 id=&#34;the-main-event&#34;&gt;The main event&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;Inference: Need to characterize posterior \(p(\theta|Y)\).&#xA;&lt;br&gt;&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;Unfortunately, for many interesting models it is not possible to&#xA;evaluate the moments and quantiles of the posterior \(p(\theta|Y)\)&#xA;analytically.&lt;/p&gt;&#xA; &lt;br&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;&lt;strong&gt;Rules of game&lt;/strong&gt;: we can only numerically evaluate prior \(p(\theta)\)&#xA;and likelihood \(p(Y|\theta)\).&lt;/p&gt;&#xA; &lt;br&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;To evaluate posterior moments of function \(h(\theta)\), we need numerical&#xA;techniques.&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;estimating-posterior-moments&#34;&gt;Estimating Posterior Moments&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;We will often abbreviate posterior distributions&#xA;\(p(\theta|Y)\) by \(\pi(\theta)\) and posterior expectations of \(h(\theta)\) by&#xA;\[&#xA;\mathbb{E}_\pi[h] = \mathbb{E}_\pi[h(\theta)] = \int h(\theta) \pi(\theta) d\theta = \int h(\theta) p(\theta|Y) d\theta.&#xA;\]&lt;/p&gt;</description>
    </item>
    <item>
      <title>Advanced MCMC: Hamiltonian Monte Carlo</title>
      <link>http://localhost:1313/teaching/bank-of-colombia-smc/lectures/10-hamiltonian-monte-carlo/</link>
      <pubDate>Fri, 11 Dec 2020 09:46:32 -0500</pubDate>
      <guid>http://localhost:1313/teaching/bank-of-colombia-smc/lectures/10-hamiltonian-monte-carlo/</guid>
      <description>&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;&#xA;&lt;h3 id=&#34;hamiltonian-monte-carlo&#34;&gt;Hamiltonian Monte Carlo&lt;/h3&gt;&#xA;&lt;p&gt;We previously spoke about how much the efficacy of MCMC algorithms&#xA;depended on the shape of the posterior.&#xA;&lt;br&gt;&#xA;We&amp;rsquo;re going to talk about posterior simulators that make that idea explicit.&#xA;&lt;br&gt;&#xA;In particular, the Hamiltonian Monte Carlo sampler described in&#xA;\cite{Neal_2011}.&lt;/p&gt;&#xA;&lt;h3 id=&#34;details&#34;&gt;Details&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Hamiltonian Monte Carlo adapts methods from the study of molecular&#xA;dynamics: &lt;em&gt;simulate the motion of molecules based on Newton&amp;rsquo;s laws&lt;/em&gt;.&#xA;&lt;br&gt;&lt;/li&gt;&#xA;&lt;li&gt;The systems which describe the evolution of molecules over time exhibit so-called&#xA;&lt;em&gt;Hamiltonian dynamics&lt;/em&gt;&#xA;&lt;br&gt;&lt;/li&gt;&#xA;&lt;li&gt;The state of the system at any point in&#xA;time is summarized by a pair \((\theta, p)\).  \(\theta\) is the location&#xA;of the molecule, while \(p\) gives its momentum (mass times velocity).&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;some-math&#34;&gt;Some Math&lt;/h3&gt;&#xA;&lt;p&gt;The evolution \(\theta\) and \(p\) is governed by set of differential&#xA;equations.  These differential equations are determined by the&#xA;&lt;em&gt;Hamiltonian&lt;/em&gt;, \(H(\theta,p)\):&lt;/p&gt;</description>
    </item>
    <item>
      <title>Introduction</title>
      <link>http://localhost:1313/teaching/bank-of-colombia-smc/lectures/00-introduction/</link>
      <pubDate>Fri, 11 Dec 2020 09:46:18 -0500</pubDate>
      <guid>http://localhost:1313/teaching/bank-of-colombia-smc/lectures/00-introduction/</guid>
      <description>&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;&#xA;&lt;h3 id=&#34;hello&#34;&gt;Hello!&lt;/h3&gt;&#xA;&lt;p&gt;My name is &lt;strong&gt;Ed Herbst.&lt;/strong&gt;  I&amp;rsquo;m currently an economist at the Federal&#xA;Reserve Board.&lt;/p&gt;&#xA;&lt;p&gt;I&amp;rsquo;m interested in (Bayesian) macroeconometrics, and I&amp;rsquo;m excited to&#xA;spend the next two weeks talking about it with you!&lt;/p&gt;&#xA;&lt;h3 id=&#34;the-next-two-weeks&#34;&gt;The next two weeks&lt;/h3&gt;&#xA;&lt;p&gt;The syllabus has a rough plan of where we&amp;rsquo;re going.&lt;/p&gt;&#xA;&lt;p&gt;But, in my experience, there is usually some re-optimization.&lt;/p&gt;&#xA;&lt;p&gt;If there&amp;rsquo;s something you&amp;rsquo;d like to talk about, or spend more (or&#xA;less) time on, just let me know.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Estimating Three DSGE Models</title>
      <link>http://localhost:1313/teaching/bank-of-colombia-smc/lectures/06-estimating-a-linear-dsge-model/</link>
      <pubDate>Fri, 11 Dec 2020 09:46:05 -0500</pubDate>
      <guid>http://localhost:1313/teaching/bank-of-colombia-smc/lectures/06-estimating-a-linear-dsge-model/</guid>
      <description>&lt;h2 id=&#34;three-dsge-models&#34;&gt;Three DSGE Models&lt;/h2&gt;&#xA;&lt;h3 id=&#34;application-1-a-new-keynesian-model-with-correlated-shocks&#34;&gt;Application 1: A New Keynesian Model with Correlated Shocks&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;The assumption that exogenous shocks evolve according to independent AR(1) is to some extent arbitrary.&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;Trying to generalize this assumption seems natural.&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;However, the more elaborate the exogenous propagation mechanism, the more difficult it becomes to disentangle endogenous from exogenous propagation.&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;This generates identification problems.&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;application-1-a-new-keynesian-model-with-correlated-shocks&#34;&gt;Application 1: A New Keynesian Model with Correlated Shocks&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;Technology growth shock \(\hat{z}_t\), government spending shock \index{government!spending shock}&#xA;\(\hat{g}_t\) evolve:&lt;/p&gt;</description>
    </item>
    <item>
      <title>Sequential Monte Carlo</title>
      <link>http://localhost:1313/teaching/bank-of-colombia-smc/lectures/05-sequential-monte-carlo/</link>
      <pubDate>Fri, 11 Dec 2020 09:45:51 -0500</pubDate>
      <guid>http://localhost:1313/teaching/bank-of-colombia-smc/lectures/05-sequential-monte-carlo/</guid>
      <description>&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;&#xA;&lt;h3 id=&#34;mcmc-what-works-and-what-doesn-t-simple-model&#34;&gt;MCMC: What works and what doesn&amp;rsquo;t, Simple Model&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;State-space representation:&lt;/p&gt;&#xA;&lt;p&gt;\begin{align}&#xA;y_t = [\begin{array}{cc} 1 &amp;amp; 1 \end{array} ] s_t, \quad&#xA;s_t = \left[ \begin{array}{cc} {\color{blue} \phi_1} &amp;amp; 0 \ {\color{blue} \phi_3} &amp;amp; {\color{blue} \phi_2} \end{array} \right] s_{t-1}&#xA;+ \left[ \begin{array}{c} 1 \ 0 \end{array} \right] \epsilon_t.&#xA;\label{eq_exss}&#xA;\end{align}&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;The state-space model can be re-written as ARMA(2,1) process&#xA;\[&#xA;(1- {\color{blue} \phi_1} L)(1-{\color{blue} \phi_2} L) y_t&#xA;= (1-({\color{blue} \phi_2} - {\color{blue} \phi_3} )L)  \epsilon_t.&#xA;\]&lt;/p&gt;</description>
    </item>
    <item>
      <title>Markov Chain Monte Carlo</title>
      <link>http://localhost:1313/teaching/bank-of-colombia-smc/lectures/04-metropolis-hastings/</link>
      <pubDate>Fri, 11 Dec 2020 09:45:35 -0500</pubDate>
      <guid>http://localhost:1313/teaching/bank-of-colombia-smc/lectures/04-metropolis-hastings/</guid>
      <description>&lt;h2 id=&#34;metropolis-hastings-algorithm&#34;&gt;Metropolis-Hastings Algorithm&lt;/h2&gt;&#xA;&lt;h3 id=&#34;the-metropolis-hastings-algorithm&#34;&gt;The Metropolis-Hastings Algorithm&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Metropolis-Hastings (MH) algorithm belongs to the class of Markov chain&#xA;Monte Carlo (MCMC) algorithms.&#xA;&lt;br&gt;&lt;/li&gt;&#xA;&lt;li&gt;Algorithm constructs a Markov chain such that the stationary distribution&#xA;associated with this Markov chain is unique and equals the posterior&#xA;distribution of interest.&#xA;&lt;br&gt;&lt;/li&gt;&#xA;&lt;li&gt;First version constructed by &lt;sup id=&#34;c23d29eb5bdb8bc2fc575e7437b8f907&#34;&gt;&lt;a href=&#34;#Metropolis1953&#34; title=&#34;Metropolis, Rosenbluth, Rosenbluth, Teller \&amp;amp; Teller, Equations of State Calculations by Fast Computing Machines, {Journal of Chemical Physics}, v(), 1087-1091 (1953).&#34;&gt;Metropolis1953&lt;/a&gt;&lt;/sup&gt;. Later&#xA;generalized by &lt;sup id=&#34;694230c3a5e9d6fd8f0276c37355f1da&#34;&gt;&lt;a href=&#34;#Hastings1970&#34; title=&#34;Hastings, Monte Carlo Sampling Methods Using Markov Chains and Their Applications, {Biometrika}, v(), 97-109 (1970).&#34;&gt;Hastings1970&lt;/a&gt;&lt;/sup&gt;.  &lt;sup id=&#34;e841d197fa5fee977a33401116803ab6&#34;&gt;&lt;a href=&#34;#Tierney1994&#34; title=&#34;Tierney, Markov Chains for Exploring Posterior Distributions, {The Annals of Statistics}, v(4), 1701-1728 (1994).&#34;&gt;Tierney1994&lt;/a&gt;&lt;/sup&gt; proved&#xA;important convergence results for MCMC algorithms.&#xA;&lt;br&gt;&lt;/li&gt;&#xA;&lt;li&gt;Introduction: &lt;sup id=&#34;a50677fe8b96e99056f5de85b8e1fdf7&#34;&gt;&lt;a href=&#34;#Chib1995a&#34; title=&#34;Chib \&amp;amp; Greenberg, Understanding the Metropolis-Hastings Algorithm, {The American Statistician}, v(), 327-335 (1995).&#34;&gt;Chib1995a&lt;/a&gt;&lt;/sup&gt;. Textbook &lt;sup id=&#34;8af5f7bb8c79b7337d6458aff47c33f6&#34;&gt;&lt;a href=&#34;#Robert2004&#34; title=&#34;Robert \&amp;amp; Casella, Monte Carlo Statistical Methods, Springer (2004).&#34;&gt;Robert2004&lt;/a&gt;&lt;/sup&gt; or&#xA;&lt;sup id=&#34;dfa786895eb8edffb49a91c754a89c01&#34;&gt;&lt;a href=&#34;#Geweke2005&#34; title=&#34;John Geweke, Contemporary Bayesian Econometrics and Statistics, John Wiley \&amp;amp; Sons, Inc. (2005).&#34;&gt;Geweke2005&lt;/a&gt;&lt;/sup&gt;.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;markov-chain-monte-carlo&#34;&gt;Markov Chain Monte Carlo&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Importance sampler generates a sequence of independent draws&#xA;from the posterior distribution \(\pi(\theta)\), the MH algorithm generates&#xA;a sequence of serially correlated draws.&#xA;&lt;br&gt;&lt;/li&gt;&#xA;&lt;li&gt;As long as the correlation in the Markov chain is not too strong, Monte&#xA;Carlo averages \index{Monte Carlo average} of these draws can accurately&#xA;approximate posterior means of \(h(\theta)\).&#xA;&lt;br&gt;&lt;/li&gt;&#xA;&lt;li&gt;We are going to care a lot about this correlation.  Why?&#xA;\[&#xA;\sqrt{n}( \bar{X} - \mathbb{E}[\bar{X}]) \Longrightarrow N \bigg( 0, \frac{1}{n} \sum_{i=1}^n \mathbb{V}[X_i] +&#xA;{\color{red} \frac{1}{n} \sum_{i=1}^n \sum_{j \not=i} COV(X_i,X_j)} \bigg)&#xA;\]&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;the-metropolis-hastings-algorithm&#34;&gt;The Metropolis Hastings Algorithm&lt;/h3&gt;&#xA;&lt;p&gt;A key ingredient is the proposal distribution \index{proposal density}&#xA;\(q(\vartheta|\theta^{i-1})\), which potentially depends on the draw&#xA;\(\theta^{i-1}\) in iteration \(i-1\) of the algorithm.&#xA;\vspace{0.05in}&lt;/p&gt;</description>
    </item>
    <item>
      <title>Introduction Bayes 6: (Linear) State Space Models</title>
      <link>http://localhost:1313/teaching/bank-of-colombia-smc/lectures/02-linear-dsge-models-and-the-kalman-filter/</link>
      <pubDate>Tue, 27 Oct 2020 21:06:35 -0400</pubDate>
      <guid>http://localhost:1313/teaching/bank-of-colombia-smc/lectures/02-linear-dsge-models-and-the-kalman-filter/</guid>
      <description>&lt;h2 id=&#34;intro&#34;&gt;Intro&lt;/h2&gt;&#xA;&lt;h3 id=&#34;background&#34;&gt;Background&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;em&gt;Textbook treatments:&lt;/em&gt; &lt;sup id=&#34;a387326a2038fd7309392dc655b58018&#34;&gt;&lt;a href=&#34;#woodford_2003&#34; title=&#34;Woodford, Interest and Prices, Princeton University Press (2003).&#34;&gt;woodford_2003&lt;/a&gt;&lt;/sup&gt;, &lt;sup id=&#34;e501ccdeda2f0731e31cee0bb583687c&#34;&gt;&lt;a href=&#34;#Gali2008&#34; title=&#34;Jordi Gal\&#39;i, Monetary Policy, Inflation, and the Business Cycle: An Introduction to the New Keynesian Framework, Princeton University Press (2008).&#34;&gt;Gali2008&lt;/a&gt;&lt;/sup&gt;&#xA;&lt;br&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;em&gt;Key empirical papers&lt;/em&gt;: &lt;sup id=&#34;29dbe0ba987d7fc6fe70b0eb8b9164a8&#34;&gt;&lt;a href=&#34;#ireland2004&#34; title=&#34;Ireland, A Method for Taking Models to the Data, {Journal of Economic Dynamics and Control}, v(6), 1205-1226 (2004).&#34;&gt;ireland2004&lt;/a&gt;&lt;/sup&gt;,  &lt;sup id=&#34;47048f0095d5c18f125a005804f82697&#34;&gt;&lt;a href=&#34;#christiano2005&#34; title=&#34;Christiano, Eichenbaum, Evans \&amp;amp; , Nominal Rigidities and the Dynamic Effects of a Shock to Monetary  Policy, {Journal of Political Economy}, v(1), 1-45 (2005).&#34;&gt;christiano2005&lt;/a&gt;&lt;/sup&gt;, &lt;sup id=&#34;0d8b307a60fe1d0ae3cf2a838eca7a27&#34;&gt;&lt;a href=&#34;#Smets2007&#34; title=&#34;Smets \&amp;amp; Wouters, Shocks and Frictions in US Business Cycles: A Bayesian DSGE Approach, {American Economic Review}, v(), 586-608 (2007).&#34;&gt;Smets2007&lt;/a&gt;&lt;/sup&gt;, &lt;sup id=&#34;188111b01398a8806c0a2b9d9be3fd1c&#34;&gt;&lt;a href=&#34;#An2007b&#34; title=&#34;An \&amp;amp; Frank Schorfheide, Bayesian Analysis of DSGE Models, {Econometric Reviews}, v(2-4), 113-172 (2007).&#34;&gt;An2007b&lt;/a&gt;&lt;/sup&gt;,&#xA;&lt;br&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;em&gt;Frequentist estimation:&lt;/em&gt; &lt;sup id=&#34;6ca9488bf724ffa1b1742c738fcd1634&#34;&gt;&lt;a href=&#34;#Harvey1991&#34; title=&#34;Andrew Harvey, Forecasting, Structural Time Series Models and the Kalman Filter, University of Cambridge Press (1991).&#34;&gt;Harvey1991&lt;/a&gt;&lt;/sup&gt;, &lt;sup id=&#34;adec714ae69bef54c5ee79cfcb41955d&#34;&gt;&lt;a href=&#34;#Hamilton&#34; title=&#34;James Hamilton, Time Series Analysis, Princeton University Press (1994).&#34;&gt;Hamilton&lt;/a&gt;&lt;/sup&gt;,&#xA;&lt;br&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;em&gt;Bayesian estimation:&lt;/em&gt; &lt;sup id=&#34;f275eaf93510eb80c8e1a928b194e45f&#34;&gt;&lt;a href=&#34;#HerbstSchorfheide2015&#34; title=&#34;Edward Herbst \&amp;amp; Frank Schorfheide, Bayesian Estimation of DSGE Models, Princeton University Press (2015).&#34;&gt;HerbstSchorfheide2015&lt;/a&gt;&lt;/sup&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;a-dsge-model&#34;&gt;A DSGE Model&lt;/h2&gt;&#xA;&lt;h3 id=&#34;small-scale-dsge-model&#34;&gt;Small-Scale DSGE Model&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Intermediate and final goods producers&#xA;&lt;br&gt;&lt;/li&gt;&#xA;&lt;li&gt;Households&#xA;&lt;br&gt;&lt;/li&gt;&#xA;&lt;li&gt;Monetary and fiscal policy&#xA;&lt;br&gt;&lt;/li&gt;&#xA;&lt;li&gt;Exogenous processes&#xA;&lt;br&gt;&lt;/li&gt;&#xA;&lt;li&gt;Equilibrium Relationships&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;final-goods-producers&#34;&gt;Final Goods Producers&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Perfectly competitive firms combine&#xA;a continuum of intermediate goods:&#xA;\[&#xA;Y_t = \left( \int_0^1 Y_t(j)^{1-\nu} dj \right)^{\frac{1}{1-\nu}}.&#xA;\]&lt;/li&gt;&#xA;&lt;li&gt;Firms take input prices \(P_t(j)\) and output prices \(P_t\) as given; maximize profits&#xA;\[&#xA;\Pi_t =  P_t \left( \int_0^1 Y_t(j)^{1-\nu} dj \right)^{\frac{1}{1-\nu}} - \int_{0}^1 P_t(j)Y_t(j)dj.&#xA;\]&lt;/li&gt;&#xA;&lt;li&gt;Demand for intermediate good \(j\):&#xA;\[&#xA;Y_t(j) = \left( \frac{P_t(j)}{P_t} \right)^{-1/\nu} Y_t.&#xA;\]&lt;/li&gt;&#xA;&lt;li&gt;Zero-profit condition implies&#xA;\[&#xA;P_t = \left( \int_0^1 P_t(j)^{\frac{\nu-1}{\nu}} dj \right)^{\frac{\nu}{\nu-1}}.&#xA;\]&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;intermediate-goods-producers&#34;&gt;Intermediate Goods Producers&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Intermediate good \(j\) is produced by a monopolist according to:&#xA;\[&#xA;Y_t(j) = A_t N_t(j).&#xA;\]&lt;/li&gt;&#xA;&lt;li&gt;Nominal price stickiness via quadratic price adjustment costs&#xA;\[&#xA;AC_t(j) = \frac{\phi}{2} \left( \frac{ P_t(j) }{ P_{t-1}(j)} - \pi \right)^2 Y_t(j).&#xA;\]&lt;/li&gt;&#xA;&lt;li&gt;Firm \(j\)&#xA;chooses its labor input \(N_t(j)\) and the price \(P_t(j)\) to maximize&#xA;the present value of future profits:&#xA;\[ \mathbb{E}_t \bigg[&#xA;\sum_{s=0}^\infty \beta^{s} Q_{t+s|t} \bigg(&#xA;\frac{P_{t+s}(j)}{P_{t+s}} Y_{t+s}(j) - W_{t+s} N_{t+s}(j) - AC_{t+s}(j) \bigg) \bigg].&#xA;\]&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;households&#34;&gt;Households&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;Household derives disutility from hours worked \(H_t\) and maximizes&lt;/p&gt;</description>
    </item>
    <item>
      <title>A Crash Course In Bayesian Inference</title>
      <link>http://localhost:1313/teaching/bank-of-colombia-smc/lectures/01-a-crash-course-in-bayesian-inference/</link>
      <pubDate>Tue, 27 Oct 2020 19:22:48 -0400</pubDate>
      <guid>http://localhost:1313/teaching/bank-of-colombia-smc/lectures/01-a-crash-course-in-bayesian-inference/</guid>
      <description>&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;&#xA;&lt;p&gt;These notes are available as slides and a Jupyter notebook.&lt;/p&gt;&#xA;&lt;h3 id=&#34;modes-of-inference&#34;&gt;Modes of Inference&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Previously, we focussed on frequentist inference (repeated sampling prodecures)&lt;/li&gt;&#xA;&lt;li&gt;measures of accuracy and performance that we used to assess the statistical procedures were pre-experimental&lt;/li&gt;&#xA;&lt;li&gt;However, many statisticians and econometricians believed that&#xA;post-experimental reasoning should be used to assess inference&#xA;procedures&lt;/li&gt;&#xA;&lt;li&gt;wherein only the actual observation \(Y^T\) is relevant and not the other observations in the sample space that could have been observed&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;example&#34;&gt;Example&lt;/h3&gt;&#xA;&lt;p&gt;Suppose \(Y_1\) and \(Y_2\) are independently and identically&#xA;distributed and&#xA;\[&#xA;P_\theta \{ Y_i = \theta-1 \} = \frac{1}{2}, \quad&#xA;P_\theta \{ Y_i = \theta+1 \} = \frac{1}{2}&#xA;\]&#xA;Consider the following confidence set&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
