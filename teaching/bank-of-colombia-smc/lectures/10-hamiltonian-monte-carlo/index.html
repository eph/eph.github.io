<!DOCTYPE html>
<html lang="en-us">
<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <title>Ed Herbst/teaching/bank-of-colombia-smc/lectures/10-hamiltonian-monte-carlo/</title>
    
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="robots" content="all,follow">
    <meta name="googlebot" content="index,follow,snippet,archive">
    <link rel="stylesheet" href="https://edherbst.net/hugo-theme-console/css/terminal-0.7.1.min.css">
    <link rel="stylesheet" href="https://edherbst.net/hugo-theme-console/css/animate-3.7.2.min.css">
    <link rel="stylesheet" href="https://edherbst.net/hugo-theme-console/css/console.css">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.5.0/css/all.min.css">
    <link rel="stylesheet" href="https://edherbst.net/css/custom.css">
<link rel="stylesheet" type="text/css" href="https://tikzjax.com/v1/fonts.css">
<script src="https://tikzjax.com/v1/tikzjax.js"></script>


    
      <!--[if lt IE 9]>
          <script src="https://oss.maxcdn.com/html5shiv/3.7.2/html5shiv.min.js"></script>
          <script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
      <![endif]-->
       <meta property="og:title" content="Advanced MCMC: Hamiltonian Monte Carlo" />
<meta property="og:description" content="" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://edherbst.net/teaching/bank-of-colombia-smc/lectures/10-hamiltonian-monte-carlo/" /><meta property="article:published_time" content="2020-12-11T09:46:32-05:00" />



<meta name="twitter:title" content="Advanced MCMC: Hamiltonian Monte Carlo"/>
<meta name="twitter:description" content="Introduction
Hamiltonian Monte Carlo
We previously spoke about how much the efficacy of MCMC algorithms
depended on the shape of the posterior.

We&rsquo;re going to talk about posterior simulators that make that idea explicit.

In particular, the Hamiltonian Monte Carlo sampler described in
\cite{Neal_2011}.
Details

Hamiltonian Monte Carlo adapts methods from the study of molecular
dynamics: simulate the motion of molecules based on Newton&rsquo;s laws.

The systems which describe the evolution of molecules over time exhibit so-called
Hamiltonian dynamics

The state of the system at any point in
time is summarized by a pair \((\theta, p)\).  \(\theta\) is the location
of the molecule, while \(p\) gives its momentum (mass times velocity).

Some Math
The evolution \(\theta\) and \(p\) is governed by set of differential
equations.  These differential equations are determined by the
Hamiltonian, \(H(\theta,p)\):"/>

</head>
<body class="terminal">
    <div class="container">
        <div class="terminal-nav">
          <header class="terminal-logo">
            <div class="logo terminal-prompt">
              
              
              
              <a href='https://edherbst.net/teaching'>teaching</a>/<a href='https://edherbst.net/teaching/bank-of-colombia-smc'>bank-of-colombia-smc</a>/<a href='https://edherbst.net/teaching/bank-of-colombia-smc/lectures'>lectures</a>/<a href='https://edherbst.net/teaching/bank-of-colombia-smc/lectures/10-hamiltonian-monte-carlo'>10-hamiltonian-monte-carlo</a>/</div></header>
          <nav class="terminal-menu">
            <ul vocab="https://schema.org/" typeof="BreadcrumbList">
                
                <li><a href="https://edherbst.net/" typeof="ListItem">&lt;/&gt;</a></li>
                
                <li><a href="https://edherbst.net/research/" typeof="ListItem">research</a></li>
                
                <li><a href="https://edherbst.net/teaching/" typeof="ListItem">teaching</a></li>
                
                <li><a href="https://edherbst.net/etc/" typeof="ListItem">et cetera</a></li>
                
            </ul>
          </nav>
        </div>
    </div>

    <div class="container animated zoomIn fast">
        
<h1>Advanced MCMC: Hamiltonian Monte Carlo</h1>
<h2 id="introduction">Introduction</h2>
<h3 id="hamiltonian-monte-carlo">Hamiltonian Monte Carlo</h3>
<p>We previously spoke about how much the efficacy of MCMC algorithms
depended on the shape of the posterior.
<br>
We&rsquo;re going to talk about posterior simulators that make that idea explicit.
<br>
In particular, the Hamiltonian Monte Carlo sampler described in
\cite{Neal_2011}.</p>
<h3 id="details">Details</h3>
<ul>
<li>Hamiltonian Monte Carlo adapts methods from the study of molecular
dynamics: <em>simulate the motion of molecules based on Newton&rsquo;s laws</em>.
<br></li>
<li>The systems which describe the evolution of molecules over time exhibit so-called
<em>Hamiltonian dynamics</em>
<br></li>
<li>The state of the system at any point in
time is summarized by a pair \((\theta, p)\).  \(\theta\) is the location
of the molecule, while \(p\) gives its momentum (mass times velocity).</li>
</ul>
<h3 id="some-math">Some Math</h3>
<p>The evolution \(\theta\) and \(p\) is governed by set of differential
equations.  These differential equations are determined by the
<em>Hamiltonian</em>, \(H(\theta,p)\):</p>
<p>\begin{eqnarray}
H(\theta,p) = \mbox{Kinetic Energy } + \mbox{Potential Energy}.
\end{eqnarray}</p>
<p>In physical systems, potential and kinetic energy are obviously
instrinsic features of the environment.
<br>
Our world:</p>
<ul>
<li>the potential energy will be pinned down by the density \(\pi(\theta)\)</li>
<li>The kinetic energy \(p\) is unrestricted, look at different kinds</li>
</ul>
<h3 id="explicit-formulation-of-hamiltonian">Explicit Formulation of Hamiltonian</h3>
<p>\begin{eqnarray}
H(\theta,p) &amp;=&amp; -\log\pi(p|\theta) - \log\pi(\theta). \nonumber \\\
&amp;=&amp; K(p,\theta) + V(\theta) \nonumber
\end{eqnarray}</p>
<p>Then the joint density of \((\theta,p)\) is given by \(e^{-H(\theta,p)}\)
<br>
As mentioned above, the \(\theta,p\) evolve over time according to the Hamiltonian equations:</p>
<p>\begin{eqnarray}
\frac{d\theta}{dt} &amp;=&amp; \frac{\partial H}{\partial p} = \frac{\partial K}{\partial p} \\\
\frac{dp}{dt} &amp;=&amp; -\frac{\partial H}{\partial \theta} = -\frac{\partial K}{\partial \theta}  -\frac{\partial V}{\partial \theta}
\end{eqnarray}</p>
<p>Note that \(-\partial V/\partial \theta = \nabla \log \pi(\theta)\), the
gradient of the log of the target density.</p>
<h3 id="a-proposal-distribution">A proposal distribution</h3>
<p>Consider now the mapping \(Q_{\bar t}(p,\theta) = (p(\bar t), \theta(\bar t))\), the mapping of
the Hamiltonian for initial state \((p, \theta)\) at time \(t = \bar t\).
<br>
The basic idea is to use this as a proposal distribution in an
Metropolis-Hastings chain which targets \(e^{-H(p, \theta)}\).
<br></p>
<h3 id="some-facts-about-q">Some Facts About Q</h3>
<ul>
<li>\(Q_{\bar t}(p, \theta)\) is deterministic and one-to-one.  So
\(Q\) has an inverse.  Neal makes the point that when
\(K(p) = K(-p)\), the inverse can be obtained via \(-Q_{\bar t}(-p, \theta)\).
<br></li>
<li>Prior to approximation \(H(p, \theta) = H(Q_{\bar t}(p, \theta))\), so the proposal is always
accepted, for any \(\bar t\).  This is because of the principal of the
conservation of energy (again, high school physics.)  In
implementation, the discretization necessary to solve the ODEs in a
general setting means \(H(p,\theta)\) will not necessarily be constant.
<br></li>
<li>The jacobian of transformation associated with \(Q_{\bar t}(p, \theta) = 1\).</li>
</ul>
<h3 id="some-intuition">Some Intuition</h3>
<p>The Hamiltonian Monte Carlo generates a Markov chain for the pair \((\theta^i,p^i)\), \(i=1,\ldots,N\).
<br>
Start with the case in which \(\pi(p|\theta)\) does not depend on \(\theta\).
Thus,
\[
H(\theta,p) = - \log \pi(p) - \log \pi(\theta).
\]
The Hamiltonian equations describe the evolution of \(\theta\) and \(p\) subject to the constraint
that \(H(\theta,p)\) (the sum of kinetic and potential energy) stays constant.</p>
<ul>
<li>
<p>if \(\pi(p^i) &gt; \pi(p^{i-1})\), it has to be the case that \(\pi(\theta^i) &lt; \pi(\theta^{i-1})\).</p>
</li>
<li>
<p>One way of thinking about this relationship is that \(p^i\) determines the level of the posterior contour from which we
are sampling and \(\theta^i\) is the location on the contour.</p>
</li>
<li>
<p>As the algorithm iterates over \(i\) we are first changing the level of the contour and then we adjust \(\theta^i\).</p>
</li>
</ul>
<h2 id="example">Example</h2>
<h3 id="an-example">An Example</h3>
<p>Suppose that \(\pi(\theta)\) corresponds to a \(N(\mu,\sigma^2)\). Thus,
\[
\log \pi(\theta) = - \frac{1}{2} \ln (2 \pi \sigma^2) - \frac{1}{2 \sigma^2} (\theta - \mu)^2.
\]
Suppose we would generate the sequence \(\theta^i\) by direct sampling. Then the level of the log posterior
density would vary according to
\[
\log \pi(\theta^i) = - \frac{1}{2} \ln (2 \pi \sigma^2) - \frac{1}{2 \sigma^2} (\theta^i - \mu)^2
\]
with</p>
<p>\begin{eqnarray*}
\mathbb{E}[\log \pi(\theta^i) ]  &amp;=&amp; - \frac{1}{2} \ln (2 \pi \sigma^2) - \frac{1}{2} \\\
\mathbb{V}[\log \pi(\theta^i) ]  &amp;=&amp; \frac{1}{2}
\end{eqnarray*}</p>
<h3 id="example-continued">Example, Continued</h3>
<p>Thus, if \(\theta^i\) is generated by direct sampling, we should
observe that the draws are \(iid\) and that the variance of the log
density is \(1/2\).
<br>
In the algorithm below, we will generate \(p^i\) by direct sampling from \(\pi(p)\), which we set to a \(N(0,M)\),
where \(M = \mathbb{V}_\pi[\theta]^{-1} = \sigma^{-2}\).
<br>
Note that in this simplified setting, the choice of \(M\) only affects
the level
\[
\mathbb{E}[ \log \pi(p^i)] = \frac{1}{2} \ln (2 \pi \sigma^2) - \frac{1}{2},
\]
but not the variance in the fluctuations around this level.</p>
<h3 id="example-continued">Example, Continued</h3>
<p>We are now in a position to solve the Hamiltonian equations, which take the form:</p>
<p>\begin{eqnarray*}
\dot{\theta} &amp;=&amp; \frac{1}{M} p \\\
\dot{p}      &amp;=&amp; -\frac{1}{\sigma^2}(\theta - \mu)
\end{eqnarray*}</p>
<p>It can be verified that the solution to this system of differential equations
takes the form</p>
<p>\begin{eqnarray*}
\theta(t) &amp;=&amp; \mu + \rho \cos \big(\alpha + t/\sqrt{\sigma^2 M} \big) \\\
p(t)      &amp;=&amp; - \rho \frac{\sqrt{M}}{\sigma} \sin \big(\alpha + t/\sqrt{\sigma^2 M} \big).
\end{eqnarray*}</p>
<h3 id="example-continued">Example, Continued</h3>
<p>Here the parameters \((\rho,\alpha)\) are determined by the initial conditions:
\[
\theta(0) = \mu + \rho \cos(\alpha), \quad p(0) = -\rho \frac{\sqrt{M}}{\sigma} \sin(\alpha),
\]
which leads to
\[
\rho = -p(0) \frac{\sigma}{\sqrt{M}} \frac{1}{\sin \alpha}, \quad
\alpha = \mbox{arctan} \left[ - \frac{p(0)/\sqrt{M}}{(\theta(0)-\mu)/\sigma} \right].
\]</p>
<h3 id="example-continued">Example, Continued</h3>
<p>We can now specify the function \(Q_{\bar t}(p, \theta)\). Using the fact that</p>
<p>\begin{eqnarray*}
\cos(x+y) &amp;=&amp; \cos x \cos y - \sin x \sin y \\\
\sin(x+y) &amp;=&amp; \sin x \cos y + \cos x \sin y,
\end{eqnarray*}</p>
<p>we obtain</p>
<p>\begin{eqnarray*}
\theta(t) - \mu &amp;=&amp; \rho \cos(\alpha) \cos(t/\sqrt{\sigma^2 M}) - \rho \sin (\alpha) \sin (t/\sqrt{\sigma^2 M}) \\\
&amp;=&amp;  (\theta(0) - \mu) \cos(t/\sqrt{\sigma^2 M}) + p(0) \frac{\sigma}{\sqrt{M}} \sin (t/\sqrt{\sigma^2 M}) \\\
p(t)      &amp;=&amp; -\rho \frac{\sqrt{M}}{\sigma} \sin(\alpha) \cos(t/\sqrt{\sigma^2 M}) -\rho \frac{\sqrt{M}}{\sigma} \cos(\alpha) \sin(t/\sqrt{\sigma^2 M}) \\\
&amp;=&amp; p(0) \cos(t/\sqrt{\sigma^2 M}) - (\theta(0)-\mu) \frac{\sqrt{M}}{\sigma} \sin(t/\sqrt{\sigma^2 M}).
\end{eqnarray*}</p>
<h3 id="example-continued">Example, Continued</h3>
<p>In matrix form, the equations can be written as
\[
\hspace{-0.2in}
\left[ \begin{array}{c} \theta(t) - \mu \ p(t) \end{array} \right]
= \left[ \begin{array}{cc} \cos(t/\sqrt{\sigma^2 M}) &amp; \frac{\sigma}{\sqrt{M}} \sin (t/\sqrt{\sigma^2 M}) \        -\frac{\sqrt{M}}{\sigma} \sin(t/\sqrt{\sigma^2 M}) &amp; \cos(t/\sqrt{\sigma^2 M}) \end{array}\right]
\left[ \begin{array}{c} \theta(0) - \mu \ p(0) \end{array} \right]
\]</p>
<h3 id="example-continued">Example, Continued</h3>
<p>It is now easy to see that the jacobian of transformation associated with \(Q_{\bar t}(p, \theta) = 1\). Moreover,</p>
<div class="latex">
  <div></div>
<p>\small</p>
<p>\begin{eqnarray*}
\lefteqn{\left[ \begin{array}{cc} \cos(t/\sqrt{\sigma^2 M}) &amp; \frac{\sigma}{\sqrt{M}} \sin (t/\sqrt{\sigma^2 M}) \         -\frac{\sqrt{M}}{\sigma} \sin(t/\sqrt{\sigma^2 M}) &amp; \cos(t/\sqrt{\sigma^2 M}) \end{array}\right]
\left[ \begin{array}{c} \theta(t) - \mu \ -p(t) \end{array} \right] } \\\
&amp;=&amp;  \left[ \begin{array}{cc} \cos(t/\sqrt{\sigma^2 M}) &amp; \frac{\sigma}{\sqrt{M}} \sin (t/\sqrt{\sigma^2 M}) \        -\frac{\sqrt{M}}{\sigma} \sin(t/\sqrt{\sigma^2 M}) &amp; \cos(t/\sqrt{\sigma^2 M}) \end{array}\right] \\\
&amp;&amp;	\times \left[ \begin{array}{cc} \cos(t/\sqrt{\sigma^2 M}) &amp; \frac{\sigma}{\sqrt{M}} \sin (t/\sqrt{\sigma^2 M}) \        \frac{\sqrt{M}}{\sigma} \sin(t/\sqrt{\sigma^2 M}) &amp; -\cos(t/\sqrt{\sigma^2 M}) \end{array}\right]
\left[ \begin{array}{c} \theta(0) - \mu \ p(0) \end{array} \right] \\\
&amp;=&amp; \left[ \begin{array}{cc} 1 &amp; 0 \ 0 &amp; -1 \end{array} \right] 	\left[ \begin{array}{c} \theta(0) - \mu \ p(0) \end{array} \right].
\end{eqnarray*}</p>
</div>
<h3 id="example-continued">Example, Continued</h3>
<p>Given the solution to the Hamiltonian equation, we can verify that \(H(\theta,p)\) stays indeed constant over time:</p>
<p>\begin{eqnarray*}
H\big( \theta(t),p(t) \big)
&amp;=&amp;  \frac{1}{2} \ln (2 \pi M) + \frac{1}{2 M} \rho^2 \frac{M}{\sigma^2} \sin^2(\cdot)
+ \frac{1}{2} \ln (2 \pi \sigma^2) + \frac{1}{2 \sigma^2} \rho^2 \cos^2(\cdot) \\\
&amp;=&amp; \frac{1}{2}  \left( \ln (2 \pi M) + \frac{1}{2} \ln (2 \pi \sigma^2) + \frac{\rho^2}{\sigma^2}  \right).
\end{eqnarray*}</p>
<p>Note that the initial values enter the level of ``energy&rsquo;&rsquo; through the parameter \(\rho\).</p>
<h3 id="the-algorithm">The Algorithm</h3>
<p>The subsequent algorithm generates the proposal distribution using the Hamiltonian equations.
In particular, it will start from
\[
\theta(0) = \theta^{i-1}, \quad p(0) \sim N(0,M).
\]
Using the Hamiltonian equations over a time interval \(t\), we obtain (in slight abuse of notation)</p>
<p>\begin{eqnarray*}
\hspace{-0.2in}
\theta^* - \mu &amp;=&amp; \cos(t/\sqrt{\sigma^2 M}) (\theta^{i-1} - \mu) + \sigma \sin (t/\sqrt{\sigma^2 M}) N(0,1)\\\
p^*            &amp;=&amp; -\frac{\sqrt{M}}{\sigma} \sin(t/\sqrt{\sigma^2 M}) (\theta^{i-1} - \mu) + \sqrt{M} \cos(t/\sqrt{\sigma^2 M}) \cdot N(0,1)
\end{eqnarray*}</p>
<h3 id="the-chain">The Chain</h3>
<p>The acceptance probability for the proposed draw depends on the
Hamiltonian. But by construction, the dynamics of \(\theta\) and \(p\) are
such that the Hamiltonian is constant, meaning the draw is always
accepted. So, we obtain the following autoregressive law of motion:
\[
\theta^{i} - \mu = \cos(t/\sqrt{\sigma^2 M}) (\theta^{i-1} - \mu) + \sigma \sin (t/\sqrt{\sigma^2 M}) \epsilon^i, \quad \epsilon^i \sim N(0,1)
\]
Because \(\sin^2 + \cos^2 = 1\), it is easy to see that the stationary
distribution of this AR(1) process is the target posterior
\(N(\mu,\sigma^2)\). The persistence of the chain depends on the time
period \(t\). When \(t\) is set to
\[
t^{iid} = \frac{\pi}{2} \sqrt{\sigma^2 M},
\]
the chain produces uncorrelated draws of \(\theta\).</p>
<h2 id="discretization">Discretization</h2>
<h3 id="discretization">Discretization</h3>
<p>To actual obtain (an approximate) \(\hat Q_{\bar t}(p, \theta)\), Hamilton&rsquo;s equations are discretized in time.
<br>
To discretize, pick a step size \(\epsilon = \Delta t\).  Then applying \(\bar t / \epsilon = L\) steps (assumed to be an integer) of the
discretized Hamiltonian obtains a draw from \(\hat Q_{\bar t}(p, \theta)\).
<br>
There are many ways approaches to discretize the ODEs!
<br>
We&rsquo;re going to use the <strong>leapfrog method</strong> because it has nice
simulation properties and the resulting density maintains the
important statistical properties</p>
<h3 id="the-leapfrog-simulator">The Leapfrog Simulator</h3>
<p>Under the assumption that
\(p|\theta\) is normally distributed with mean \(0\) and variance \(M\):</p>
<p>\begin{eqnarray}
\log\pi(p|\theta) \propto - \frac{p&rsquo;M^{-1}p}{2},
\end{eqnarray}</p>
<p>\(\partial K/\partial \theta = 0\) and
the calculations are considerably simplified.
<em>(But it&rsquo;s worth reiterating that \(\pi(p|\theta)\) is choice.)</em>
Given \(\theta(t)\) and \(p(t)\), a
step of size \(\epsilon\) is taken using the following three steps.</p>
<p>\begin{eqnarray*}
p(t+\epsilon/2) &amp;=&amp; p(t) + \frac{\epsilon}{2}\nabla \log \pi(\theta(t)) \\\
\theta(t+\epsilon) &amp;=&amp; \theta(t) + \epsilon M^{-1}p(t+\epsilon/2) \\\
p(t+\epsilon) &amp;=&amp; p(t+\epsilon/2) + \frac{\epsilon}{2}\nabla \log \pi(\theta(t+\epsilon)).
\end{eqnarray*}</p>
<h3 id="the-details">The Details</h3>
<p>This leads to the following algorithm (the user needs to specify \(\epsilon\) and \(L\)):
<br></p>
<p>\begin{algo}{Modified Leapfrog Simulator,
\label{algo:leapfrog}
$\hat Q_{L\epsilon}(\cdot,\cdot)$.}  This algorithm takes as an
inputs $(\theta, p)$ and returns $(\theta^*, p^*)$, after
approximating Hamiltonion dynamics using step size $\epsilon$
for $L$ steps.
\begin{enumerate}
\item For $l = 1, \ldots, L$. Set
\begin{eqnarray*}
&amp;1.&amp; p \leftarrow p + \epsilon \nabla \log \pi(\theta)/2 \\\
&amp;2.&amp; \theta \leftarrow \theta + \epsilon M^{-1} p \\\
&amp;3.&amp; p \leftarrow p + \epsilon \nabla \log \pi(\theta) / 2
\end{eqnarray*}
\item  Return $\theta^* = \theta$ and $p^* = -p$.  (The negation is not a typo!)
\end{enumerate}
\end{algo}</p>
<h3 id="leapfrog-simulator">Leapfrog Simulator</h3>
<p>\includegraphics[width=4in]{static/leapfrog_neal}</p>
<h3 id="back-to-the-example">Back to the Example</h3>
<p>For the example given above, we have</p>
<p>\begin{eqnarray*}
\left[
\begin{array}{c}
\theta^* - \mu \ p^*
\end{array}
\right] &amp;=&amp;
\left[
\begin{array}{cc}
1 &amp; 0 \ 0 &amp; -1
\end{array}
\right]
\left[\begin{matrix}1 - \frac{\epsilon^{2}}{2 M \sigma^{2}} &amp; \frac{\epsilon}{M}\- \frac{\epsilon}{\sigma^{2}} + \frac{\epsilon^{3}}{4 M \sigma^{4}} &amp; 1 - \frac{\epsilon^{2}}{2 M \sigma^{2}}\end{matrix}\right]^L
\left[
\begin{array}{c}
\theta^{i-1} - \mu \ \hat p
\end{array}
\right]                                                                             \end{eqnarray*}</p>
<p>The stability of this system is determined by the eigenvalues \(\lambda_1\) and \(\lambda_2\), where</p>
<p>\begin{eqnarray}
\lambda_1 &amp;= \frac{2 M \sigma^{2} - \epsilon^{2}}{2 M \sigma^{2}} + \frac{\epsilon}{2 M \sigma^{2}} \sqrt{- 4 M \sigma^{2} + \epsilon^{2}}, \nonumber \\\
\lambda_2 &amp;= \frac{2 M \sigma^{2} - \epsilon^{2}}{2 M \sigma^{2}} - \frac{\epsilon}{2 M \sigma^{2}} \sqrt{- 4 M \sigma^{2} + \epsilon^{2}} \nonumber
\end{eqnarray}</p>
<h3 id="example-continued">Example, Continued</h3>
<p><strong>Case 1:</strong> \(\epsilon &gt; \sqrt{4M\sigma^2}\). Then</p>
<p>\begin{eqnarray*}
\lambda_2 &amp;=&amp; 1 - \frac{\epsilon^2}{2M\sigma^2} - \frac{\epsilon}{4M\sigma^2}\sqrt{- 4 M \sigma^{2} + \epsilon^{2}} \\\
&amp;&lt;&amp; 1 - \frac{\epsilon^2}{2M\sigma^2} \\\
&amp;&lt;&amp; 1 - \frac{4M\sigma^2}{2M\sigma^2} \\\
&amp;&lt;&amp; -1
\end{eqnarray*}</p>
 <br>
**Case 2:** \\(\epsilon \le \sqrt{4M\sigma^2}\\). Then the eigenvalues
are complex conjugates.  A quick calculation reveals that \\(|\lambda\_i|
   = 1\\) for \\(i = 1,2\\). So the system is stable.
<h3 id="remarks">Remarks:</h3>
<ul>
<li>It is clear from the above calculations that if the step size is
too big \((&gt; 2\sqrt{M\sigma^2})\),  \(|\lambda_2| &gt; 1\), so the leapfrog
simulator will explode.
<br></li>
<li>On the other hand, step size can&rsquo;t really be ``too small&rsquo;&rsquo; in
the sense that the system will be stable for any \(\epsilon &lt;
4\sqrt{M\sigma^2}\).
<br></li>
<li>Setting \(M = \sigma^{-2}\), is optimal in the sense that the
stability of the system is so no longer dependent on any features
of the posterior.
<br></li>
<li>Finally, note that the number of steps, \(L\), is irrelevant with
respect to the stability properties of the simulator.</li>
</ul>
<h2 id="acceptance-rates">Acceptance Rates</h2>
<h3 id="what-is-the-right-acceptance-rate">What is the Right Acceptance Rate?</h3>
<p>For any Metropolis-style algorithm
for \(x \sim \pi\) with proposal density \(q(x^* | x)\), note the
expected (unbounded) acceptance probability is given by:</p>
<p>\begin{eqnarray}
E\left[\frac{\pi(x^*)q(x|x^*)}{\pi(x)q(x^*|x)}\right]
&amp;=&amp;
\int\int\frac{\pi(x^*)q(x|x^*)}{\pi(x)q(x^*|x)}
q(x^*|x) \pi(x) dx dx^* \nonumber \\\
&amp;=&amp; \int \pi(x^*)\left[\int q(x|x^*) dx\right]
dx^* \nonumber \\\
&amp;=&amp; \int \pi(x^*)dx^*  \nonumber \\\
&amp;=&amp; 1.
\end{eqnarray}</p>
<h3 id="some-analytics">Some Analytics</h3>
<p>Note that for both the Random Walk Metropolis-Hastings (RWMH) algorithm \((x = \theta)\) and the Hamiltonian Monte Carlo algorithm \((x = (\theta,p))\),
we have \(q(x|x^*) = q(x^*|x)\).  This means we can deduce that</p>
<p>\begin{eqnarray}
\label{eq:pratio}
E\left[\frac{\pi(x^*)}{\pi(x)}\right] = 1.
\end{eqnarray}</p>
<p>If we write the posterior in the form, \(\pi(x) = \exp(-f(x))/Z\), then using
(\ref{eq:pratio}), we deduce that</p>
<p>\begin{eqnarray}
\label{eq:pratio}
E\left[\exp\left\{-(f(x^*) - f(x))\right\}\right] = 1.
\end{eqnarray}</p>
<h3 id="analytics-continued">Analytics, Continued</h3>
<p>Defining \(\Delta = f(x^*) - f(x)\) and using Jensen&rsquo;s inequality, we
have:</p>
<p>\begin{eqnarray}
\label{eq:delta}
E\left[\Delta\right] \ge 0.
\end{eqnarray}</p>
<p>In most interesting cases, the inequality is strict. Next, note also that \(\alpha(x^*|x)\), the Metropolis-Hastings
acceptance probability is given by:</p>
<p>\begin{eqnarray}
\label{eq:alpha}
\alpha(x^*|x) = \min\left\{1,\exp(-\Delta)\right\}.
\end{eqnarray}</p>
<h3 id="analytics-continued">Analytics, Continued</h3>
<p>The expected acceptance rate for an MH algorithm can be
written as
\tiny</p>
<p>\begin{eqnarray}
\hspace{-2.4in}
\label{eq:avgacpt}
\bar \alpha &amp;=&amp; \int \alpha(x^* | x) q(x^*|x) \pi(x) dx^* dx
\nonumber \\\
&amp;=&amp; \int_{\Delta(x^*,x) &lt; 0} \alpha(x^* | x) q(x^*|x) \pi(x) dx^* dx
+ \int_{\Delta(x^*,x) &gt; 0} \alpha(x^* | x) q(x^*|x) \pi(x)
dx^* dx\nonumber \\\
&amp;=&amp; \int_{\Delta(x^*,x) &lt; 0} \alpha(x^*| x) q(x^*|x) \pi(x) dx^* dx
+ \int_{\Delta(x^*,x) &gt; 0} \alpha(x | x^*) q(x|x^*) \pi(x^*)
dx^* dx\nonumber \\\
&amp;=&amp; \int_{\Delta(x^*,x) &lt; 0} \alpha(x^*| x) q(x^*|x) \pi(x) dx^* dx
+ \int_{\Delta(x,x^*) &lt; 0} \alpha(x | x^*) q(x|x^*) \pi(x^*)
dx^* dx\nonumber \\\
&amp;=&amp; \int_{\Delta(x^*,x) &lt; 0}  q(x^*|x) \pi(x) dx^* dx +
\int_{\Delta(x,x^*) &lt; 0} q(x|x^*) \pi(x^*)
dx^* dx\nonumber \\\
&amp;=&amp; 2 \times {\mathbb P}(\Delta &lt; 0).
\end{eqnarray}</p>
<h3 id="properties-of-delta">Properties of Delta</h3>
<p>In what follows, we first
derive a restriction on the relationship between the mean and variance
of \(\Delta\).  If we assume the elements of \(x\), \(x_i\), are independent
we can write,</p>
<p>\begin{eqnarray}
\label{eq:f}
f(x) = \sum_{d=1}^D f_d(x_d) \mbox{ and } \Delta = \sum_{d=1}^D \Delta_d,
\end{eqnarray}</p>
<p>where \(D\) is the size of x.  Taking a second-order expansion around
\(\exp(-\Delta_d)\), we have:</p>
<p>\begin{eqnarray}
\exp(-\Delta_d) \approx  1 - \Delta_d + \Delta_d^2/2.
\end{eqnarray}</p>
<p>Using (\ref{eq:f}), $E[Δ_d] ≈ E[Δ^2_d]/2.$  This means
the mean of \(\Delta_d\) is about half of the variance of \(\Delta^2_d\).
If we further assume that the proposals are independent, this means
that \(E[\Delta] \approx E[\Delta^2]/2\).</p>
<h3 id="asymptotics">Asymptotics</h3>
<p>write \(\mu = E[\Delta]\),
\[
\Delta \sim N(\mu, 2\mu).
\]
Using this, we can write:</p>
<p>\begin{eqnarray}
\label{eq:abar}
\bar \alpha &amp;=&amp; 2 \times {\mathbb P}(\Delta &lt; 0) \nonumber \\\
&amp;=&amp; 2 \Phi\left(\frac{0 - \mu}{\sqrt{2\mu}}\right)
\nonumber \\\
&amp;=&amp; 2 \Phi(-\sqrt{\mu/2}).
\end{eqnarray}</p>
<p>Finally, we use this to construct a (heuristic) cost of an
algorithm:</p>
<p>\begin{eqnarray}
\label{eq:cost}
\mbox {Cost of Alg.} &amp;\propto&amp; \mbox{Avg. Number of Proposals
Before Acceptance} \nonumber \\\
&amp;~&amp; \times \mbox{ Proposal Steps to <code>Independent'' Point} \nonumber \\\\\\ &amp;=&amp; \frac{1}{\bar \alpha} \times \mbox{ Proposal Steps to </code>Independent&rsquo;&rsquo; Point}
\end{eqnarray}</p>
<h3 id="mu--for-rwmh-dot">\(\mu\) for RWMH.</h3>
<p>Consider the RWMH applied
to a independent multivariate normal distribution of size \(D\).  So
\(x \sim N(0,I_D)\) and \(q(x^*|x) \sim N(x,c^2 I_D)\). Then:
\[
E[\Delta] = E\left[\sum_{d=1}^D \Delta_d\right] = \sum_{d=1}^D E[\Delta_d] = \frac{c^2}{2}D.
\]
Informally, this probability is decreasing as \(D\) increases, since the
expected difference \(E[\Delta] \propto D\) with fixed \(c\).
<br>
This means to maintain a given acceptance rate as \(D\) increases, \(c\) must shrink
at rate \(D^{-1/2}\).</p>
<h3 id="rwmh-continued">RWMH Continued</h3>
<p>Finally for random walk processes, it is well
known that the number of steps needed to reach a ``nearly
independent&rsquo;&rsquo; point will be proportional to \(c^{-2}\).  We can then
write the cost, \(C_{RWMH}\), as:</p>
<p>\begin{eqnarray}
\label{eq:cost-rwmh}
C_{RWMH} = \frac{1}{2\Phi(-\sqrt{\mu/2})}\times \frac{1}{\mu}.
\end{eqnarray}</p>
<p>This cost is minimized when \(\mu = 2.83\), which implies as
\(\bar\alpha = 0.234\), in accordance with well known results.</p>
<h3 id="mu--for-hmc-dot">\(\mu\) for HMC.</h3>
<p>Now \(f(\theta,p)\) can be written as:
\[
f(\theta, p) = \frac{\theta^2}{2} + \frac{p^2}{2}
\]
Applying <em>many</em> leapfrog steps \(L\) leads to:
\[
E[\Delta] \approx D\epsilon^4.
\]
This means that as \(D\) increases, \(\epsilon\) must shrink at rate
\(D^{-1/4}\) in order to maintain a reasonable acceptance rate.
<br>
The number of leapfrog updates to reach a nearly independent point
will grow at rate \(\epsilon\).</p>
<h3 id="hmc-acceptance-rate">HMC Acceptance Rate</h3>
<p>Using the above relationship, \(\mu
\propto \epsilon^{1/4}\).  Thus:</p>
<p>\begin{eqnarray}
\label{eq:cost-HMC}
C_{HMC} = \frac{1}{2\Phi(-\sqrt{\mu/2})}\times \frac{1}{\mu^{1/4}}.
\end{eqnarray}</p>
<p>This cost is minimized when \(\mu = 0.41\), which implies as
\(\bar\alpha = 0.65\).  Hence, one should target an acceptance rate of
about 65%.</p>
<h2 id="mcmc">MCMC</h2>
<h3 id="mcmc-with--euclidean--hamiltonian-proposal-dot">MCMC with (Euclidean) Hamiltonian Proposal.</h3>
<p>We now combine the components
to obtain a Hamiltonian Monte Carlo algorithm.
Our goal is to obtain draws from \(\pi(\theta)\). To do so, we target the augmented distribution:
\[
\pi(\theta,p) = \pi(\theta)\underbrace{\pi(p|\theta)}_{\mathcal N(0, M).} = \exp\{-H(\theta,p)\}.
\]
Given \((\theta^{i-1}, p^{i-1})\), we apply two Markov transition
kernels in succession to get \((\theta^i, p^i)\).  The two-step process
first operates on \(p\) and then \((\theta, p)\) jointly.</p>
<h3 id="a-two-step-process">A Two Step Process</h3>
<ol>
<li>First, draw \(\hat p \sim \mathcal N(0, M)\).  This draw is
always ``accepted&rsquo;&rsquo; because this in fact coincides with true
marginal distribution of \(\pi(p|\theta)\).</li>
<li>Second, given \((\theta^{i-1}, \hat p)\).  Draw
\((\theta^*, p^*)\) by applying the (approximate) Hamiltonian
mapping using the \(\hat Q_{\bar t = L\epsilon}(\theta,p)\).  Note
that this is deterministic.  We use the leap frog method with a
twist.</li>
</ol>
<p>Of course, in practice this is implemented in a one-step procedure.
In fact, there is no need to store draws of \(p\).</p>
<p>In our applications, we should try to have \(M\) approximate
\(\mathbb V_{\pi}[\theta]^{-1}\).  And, of course, we also need an initial
\(\theta\).</p>
<h3 id="some-details">Some Details</h3>
<p>An important thing to note about this proposal is that,
\[
\hat Q_{L\epsilon}(\hat Q_{L\epsilon}(\theta^{i-1}, \hat p)) = (\theta^{i-1}, \hat p).
\]
In this sense the mapping is symmetric.
<br>
Moreover, the Jacobian
associated with \(Q_{L\epsilon}\) is 1.  The upshot of this is
that we don&rsquo;t need to account for \(Q_{L\epsilon}\) in the
Metropolis-Hastings acceptance probability, which is given by:</p>
<p>\begin{eqnarray}
\label{eq:hmc-alpha}
\alpha = \max\left\{1, \exp\left( H(\theta^{i-1}, \hat p)- H(\theta^*, p^*)\right)\right\}
= \max\left\{1, \frac{\pi(\theta^*, p^*)}{\pi(\theta^{i-1}, \hat p)}\right\}.
\end{eqnarray}</p>
<p>Note that the Hamiltonian equations ensure that the ratio \(\pi(\theta^*, p^*)/\pi(\theta^{i-1},\hat p)\), and therefore the acceptance ratio, is close to one. Because of the discretization, however, in the practical implementation the ratio is not equal to one.</p>
<h2 id="example">Example</h2>
<h3 id="example">Example</h3>
<p>Consider the circular posterior density
\[
\pi(\theta) \propto \exp \bigg \{ -\frac{1}{2}\psi_n \big((\theta_1-1)^2 + (\theta_2-1)^2 -1  \big)
^2 \bigg \}{\bf 1}\left\{\theta\in[-1,3]^2\right\}
\]
This means that:</p>
<p>\begin{multline}</p>
<p>\nabla \log \pi(\theta) = \bigg[- 2 \psi_n \left(\theta_{1} - 1\right) \left(\left(\theta_{1} - 1\right)^{2} + \left(\theta_{2} - 1\right)^{2} - 1\right), \\\</p>
<ul>
<li>2 \psi_n \left(\theta_{2} - 1\right) \left(\left(\theta_{1} - 1\right)^{2} + \left(\theta_{2} - 1\right)^{2} - 1\right)\bigg].
\end{multline}</li>
</ul>
<p>With \(\psi_n = 1000\), the ``posterior&rsquo;&rsquo; covariance of this distribution is:</p>
<p>\begin{eqnarray*}
\mathbb V_{\pi}[\theta] = \left[\begin{array}{cc} 0.5 &amp; 0 \ 0 &amp; 0.5 \end{array}\right].
\end{eqnarray*}</p>
<h3 id="let--n-50000-l-10-epsilon-0-dot-01--dot">Let \(N = 50000, L = 10, \epsilon = 0.01\).</h3>
<p>\begin{center}
\includegraphics[width=4.5in]{static/results}
\end{center}</p>
<h3 id="going-beyond-hamiltonian">Going Beyond Hamiltonian</h3>
<ul>
<li>Sometimes the leapfrog set is inefficient.  Going around in circles!
<br></li>
<li>Modification: &ldquo;No U-Turn Sampler&rdquo; (NUTS) of \cite{Hoffman_Gelman_2014}
<br></li>
<li>This is the backbone of the popular &ldquo;probabilistic programming language&rdquo; <a href="https://mc-stan.org/">Stan</a>.
<br></li>
<li>Provide interface (and automatic differentiate) for many popular
random variables (and hence Bayesian models)</li>
</ul>
<h2 id="beyond">Beyond</h2>
<h3 id="can-this-work-for-dsge-models">Can this work for DSGE models?</h3>
<p>It seems like this should be great for DSGE models right?
<br>
Well, we need to compute \(\nabla \log \pi(\theta)\).  Not to easy for a DSGE!</p>
<ul>
<li>Numerical? Noisy, Slow</li>
<li>Analytic? Slow, Explosive</li>
<li>Automatic? Accurate but slow, issues with complex roots
<br></li>
</ul>
<p>Also, multimodality is still present!  Can combine SMC with HMC!</p>
<h2 id="references">References</h2>
<h3 id="references">References</h3>
<p>&lt;/home/eherbst/Dropbox/ref/ref.bib&gt;</p>



<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  TeX: { equationNumbers: { autoNumber: "AMS" },
         extensions: ["AMSmath.js", "AMSsymbols.js"] },
  tex2jax: {
      inlineMath: [['$','$'],['\\(','\\)']],
      displayMath: [['$$','$$'], ['\\[', '\\]']],
    processEscapes: true,
    processEnvironments: true,
    skipTags: ['script', 'noscript', 'style', 'textarea', 'pre']
  }
});
</script>
<script type="text/javascript"
  src="//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>


        <div class="footer">
    Powered by <a href="https://gohugo.io/">Hugo</a> with
    <a href="https://github.com/mrmierzejewski/hugo-theme-console/">Console Theme</a>. 
</div>

    </div>
  </body>
</html>
